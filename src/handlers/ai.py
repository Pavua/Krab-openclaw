# -*- coding: utf-8 -*-
"""
AI Handler ‚Äî –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ –∫–æ–º–∞–Ω–¥, —Å–≤—è–∑–∞–Ω–Ω—ã—Ö —Å AI: –∞–≤—Ç–æ-–æ—Ç–≤–µ—Ç, reasoning, –∞–≥–µ–Ω—Ç–Ω—ã–π —Ü–∏–∫–ª.

–ò–∑–≤–ª–µ—á—ë–Ω –∏–∑ main.py. –í–∫–ª—é—á–∞–µ—Ç:
- auto_reply_logic: —É–º–Ω—ã–π –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫ –Ω–∞ –≤—Ö–æ–¥—è—â–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
- !think: Reasoning Mode (–≥–ª—É–±–æ–∫–æ–µ —Ä–∞–∑–º—ã—à–ª–µ–Ω–∏–µ)
- !smart: Agent Workflow (–∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ –∑–∞–¥–∞—á)
- !code: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞
- !learn: –æ–±—É—á–µ–Ω–∏–µ RAG
- !exec: Python REPL (Owner only)
"""

import os
import sys
import time
import asyncio
import traceback
import inspect
import shlex
import re
from io import StringIO
from dataclasses import dataclass
from collections import deque
from typing import Any

from pyrogram import filters, enums
from pyrogram.types import Message
from pyrogram import raw, utils as pyro_utils

from .auth import is_owner, is_authorized, is_superuser
from ..core.markdown_sanitizer import sanitize_markdown_for_telegram, strip_backticks_from_content
from ..core.reaction_learning import ReactionLearningEngine

import structlog
logger = structlog.get_logger(__name__)

def _timeout_from_env(name: str, default_value: int) -> int:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–∞–π–º–∞—É—Ç –∏–∑ env —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º fallback."""
    raw = os.getenv(name, str(default_value)).strip()
    try:
        parsed = int(raw)
        return parsed if parsed > 0 else default_value
    except Exception:
        return default_value


# –í auto-reply –¥–µ—Ä–∂–∏–º –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—â—É—Ç–∏–º–æ –Ω–∏–∂–µ, —á–µ–º –≤ !think/agent-flow,
# —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –Ω–µ –≤–∏–¥–µ–ª ¬´ü§î –î—É–º–∞—é‚Ä¶¬ª –ø–æ 10-15 –º–∏–Ω—É—Ç –ø—Ä–∏ –¥–µ–≥—Ä–∞–¥–∞—Ü–∏–∏ cloud.
AUTO_REPLY_TIMEOUT_SECONDS = _timeout_from_env("AUTO_REPLY_TIMEOUT_SECONDS", 240)
THINK_TIMEOUT_SECONDS = _timeout_from_env("THINK_TIMEOUT_SECONDS", 420)
AUTO_REPLY_CONTEXT_TOKENS = _timeout_from_env("AUTO_REPLY_CONTEXT_TOKENS", 3000)
AUTO_REPLY_BUSY_NOTICE_SECONDS = _timeout_from_env("AUTO_REPLY_BUSY_NOTICE_SECONDS", 12)
AUTO_REPLY_QUEUE_ENABLED = str(os.getenv("AUTO_REPLY_QUEUE_ENABLED", "1")).strip().lower() in {
    "1", "true", "yes", "on"
}
AUTO_REPLY_QUEUE_MAX_PER_CHAT = _timeout_from_env("AUTO_REPLY_QUEUE_MAX_PER_CHAT", 50)
AUTO_REPLY_QUEUE_NOTIFY_POSITION = str(
    os.getenv("AUTO_REPLY_QUEUE_NOTIFY_POSITION", "1")
).strip().lower() in {"1", "true", "yes", "on"}
AUTO_REPLY_FORWARD_CONTEXT_ENABLED = str(
    os.getenv("AUTO_REPLY_FORWARD_CONTEXT_ENABLED", "1")
).strip().lower() in {"1", "true", "yes", "on"}
try:
    AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS = float(
        str(os.getenv("AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS", "1.8")).strip() or "1.8"
    )
    if AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS < 0.4:
        AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS = 0.4
except Exception:
    AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS = 1.8
AUTO_REPLY_FORWARD_BURST_MAX_ITEMS = _timeout_from_env("AUTO_REPLY_FORWARD_BURST_MAX_ITEMS", 8)
AUTO_REPLY_QUEUE_MAX_RETRIES = max(
    0,
    int(str(os.getenv("AUTO_REPLY_QUEUE_MAX_RETRIES", "1")).strip() or "1"),
)
AUTO_REPLY_GROUP_AUTHOR_ISOLATION_ENABLED = str(
    os.getenv("AUTO_REPLY_GROUP_AUTHOR_ISOLATION_ENABLED", "1")
).strip().lower() in {"1", "true", "yes", "on"}
REACTION_LEARNING_ENABLED = str(os.getenv("REACTION_LEARNING_ENABLED", "1")).strip().lower() in {
    "1", "true", "yes", "on"
}
CHAT_MOOD_ENABLED = str(os.getenv("CHAT_MOOD_ENABLED", "1")).strip().lower() in {
    "1", "true", "yes", "on"
}
AUTO_REACTIONS_ENABLED = str(os.getenv("AUTO_REACTIONS_ENABLED", "1")).strip().lower() in {
    "1", "true", "yes", "on"
}
REACTION_LEARNING_WEIGHT = float(str(os.getenv("REACTION_LEARNING_WEIGHT", "0.35")).strip() or "0.35")
AUTO_REPLY_STREAM_EDIT_INTERVAL_SECONDS = float(
    str(os.getenv("AUTO_REPLY_STREAM_EDIT_INTERVAL_SECONDS", "1.2")).strip() or "1.2"
)
AUTO_REPLY_HISTORY_SYNC_TIMEOUT_SECONDS = float(
    str(os.getenv("AUTO_REPLY_HISTORY_SYNC_TIMEOUT_SECONDS", "8")).strip() or "8"
)
AUTO_REPLY_CONTINUE_ON_INCOMPLETE = str(
    os.getenv("AUTO_REPLY_CONTINUE_ON_INCOMPLETE", "1")
).strip().lower() in {"1", "true", "yes", "on"}
AUTO_REPLY_SELF_PRIVATE_ENABLED = str(
    os.getenv("AUTO_REPLY_SELF_PRIVATE_ENABLED", "1")
).strip().lower() in {"1", "true", "yes", "on"}
try:
    AUTO_REPLY_MAX_NUMBERED_LIST_ITEMS = max(
        0,
        int(str(os.getenv("AUTO_REPLY_MAX_NUMBERED_LIST_ITEMS", "0")).strip() or "0"),
    )
except Exception:
    AUTO_REPLY_MAX_NUMBERED_LIST_ITEMS = 0
AUTO_REPLY_MAX_RESPONSE_CHARS = _timeout_from_env("AUTO_REPLY_MAX_RESPONSE_CHARS", 1800)
AUTO_REPLY_MAX_RESPONSE_CHARS_PRIVATE = _timeout_from_env(
    "AUTO_REPLY_MAX_RESPONSE_CHARS_PRIVATE",
    2400,
)

AUTO_SUMMARY_ENABLED = str(os.getenv("AUTO_SUMMARY_ENABLED", "0")).strip().lower() in {
    "1", "true", "yes", "on"
}

# –ó–∞—â–∏—Ç–∞ –æ—Ç –¥—É–±–ª–µ–π update.
_LAST_BUSY_NOTICE_TS = {}
_RECENT_MESSAGE_MARKERS = {}
_RECENT_MESSAGE_TTL_SECONDS = 180
_FORWARD_BURST_CONTEXT_MAP: dict[str, str] = {}


@dataclass
class ChatQueuedTask:
    """–û–¥–Ω–∞ –∑–∞–¥–∞—á–∞ –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç–∞ –≤ –æ—á–µ—Ä–µ–¥–∏ —á–∞—Ç–∞."""

    chat_id: int
    message_id: int
    received_at: float
    priority: int
    runner: Any
    attempt: int = 0


class ChatWorkQueue:
    """
    FIFO –æ—á–µ—Ä–µ–¥—å –∑–∞–¥–∞—á –ø–æ —á–∞—Ç–∞–º.
    –û–¥–∏–Ω worker –Ω–∞ —á–∞—Ç, –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –≤—Ö–æ–¥—è—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π.
    """

    def __init__(self, max_per_chat: int = 50, max_retries: int = 1):
        self.max_per_chat = max(1, int(max_per_chat))
        self.max_retries = max(0, int(max_retries))
        self._queues: dict[int, deque[ChatQueuedTask]] = {}
        self._workers: dict[int, asyncio.Task] = {}
        self._active_task: dict[int, ChatQueuedTask] = {}
        self._processed = 0
        self._failed = 0
        self._retried = 0

    def set_max_per_chat(self, value: int) -> None:
        self.max_per_chat = max(1, int(value))

    def enqueue(self, task: ChatQueuedTask) -> tuple[bool, int]:
        queue = self._queues.setdefault(int(task.chat_id), deque())
        if len(queue) >= self.max_per_chat:
            return False, len(queue)
        queue.append(task)
        return True, len(queue)

    def ensure_worker(self, chat_id: int) -> None:
        worker = self._workers.get(int(chat_id))
        if worker and not worker.done():
            return
        self._workers[int(chat_id)] = asyncio.create_task(self._worker_loop(int(chat_id)))

    async def _worker_loop(self, chat_id: int) -> None:
        while True:
            queue = self._queues.get(chat_id)
            if not queue:
                self._workers.pop(chat_id, None)
                return
            task = queue.popleft()
            self._active_task[chat_id] = task
            should_stop = False
            try:
                logger.debug(
                    "queue: —Å—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏",
                    chat_id=chat_id,
                    message_id=task.message_id,
                    attempt=task.attempt,
                    queue_left_after_pop=len(queue),
                )
                await task.runner()
                self._processed += 1
                logger.debug(
                    "queue: –∑–∞–¥–∞—á–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —É—Å–ø–µ—à–Ω–æ",
                    chat_id=chat_id,
                    message_id=task.message_id,
                    processed=self._processed,
                )
            except Exception:
                if task.attempt < self.max_retries:
                    task.attempt += 1
                    queue.appendleft(task)
                    self._retried += 1
                    logger.warning(
                        "–ü–æ–≤—Ç–æ—Ä –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥–∏ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏",
                        chat_id=chat_id,
                        message_id=task.message_id,
                        attempt=task.attempt,
                        max_retries=self.max_retries,
                    )
                else:
                    self._failed += 1
                    logger.exception(
                        "–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥–∏",
                        chat_id=chat_id,
                        message_id=task.message_id,
                        attempt=task.attempt,
                    )
            finally:
                self._active_task.pop(chat_id, None)
                if not queue:
                    # –ï—Å–ª–∏ –æ—á–µ—Ä–µ–¥—å –ø—É—Å—Ç–∞ ‚Äî —Å–Ω–∏–º–∞–µ–º –µ–µ, —á—Ç–æ–±—ã –Ω–µ –¥–µ—Ä–∂–∞—Ç—å –ª–∏—à–Ω–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ.
                    self._queues.pop(chat_id, None)
                    self._workers.pop(chat_id, None)
                    should_stop = True
            if should_stop:
                return

    def get_stats(self) -> dict:
        queue_lengths = {str(chat_id): len(q) for chat_id, q in self._queues.items()}
        return {
            "processed": int(self._processed),
            "failed": int(self._failed),
            "retried": int(self._retried),
            "active_chats": len(self._workers),
            "queue_lengths": queue_lengths,
            "queued_total": int(sum(queue_lengths.values())),
            "max_per_chat": int(self.max_per_chat),
            "max_retries": int(self.max_retries),
        }


class AIRuntimeControl:
    """Runtime-–∫–æ–Ω—Ç—Ä–æ–ª–ª–µ—Ä –ø–æ–ª–∏—Ç–∏–∫–∏ AI-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ (–æ—á–µ—Ä–µ–¥—å, guardrails, —Ä–µ–∞–∫—Ü–∏–∏)."""

    def __init__(self, queue_manager: ChatWorkQueue, reaction_engine: ReactionLearningEngine, router):
        self.queue_manager = queue_manager
        self.reaction_engine = reaction_engine
        self.router = router
        self.queue_enabled = AUTO_REPLY_QUEUE_ENABLED
        self.queue_notify_position_enabled = AUTO_REPLY_QUEUE_NOTIFY_POSITION
        self.forward_context_enabled = AUTO_REPLY_FORWARD_CONTEXT_ENABLED
        self.reaction_learning_enabled = REACTION_LEARNING_ENABLED
        self.chat_mood_enabled = CHAT_MOOD_ENABLED
        self.auto_reactions_enabled = AUTO_REACTIONS_ENABLED
        self.group_author_isolation_enabled = AUTO_REPLY_GROUP_AUTHOR_ISOLATION_ENABLED
        self.continue_on_incomplete_enabled = AUTO_REPLY_CONTINUE_ON_INCOMPLETE
        self.last_context_snapshot: dict[str, dict] = {}

    def set_queue_enabled(self, enabled: bool) -> None:
        self.queue_enabled = bool(enabled)

    def set_queue_notify_position_enabled(self, enabled: bool) -> None:
        self.queue_notify_position_enabled = bool(enabled)

    def set_queue_max(self, max_per_chat: int) -> None:
        self.queue_manager.set_max_per_chat(max_per_chat)

    def set_queue_max_retries(self, max_retries: int) -> None:
        self.queue_manager.max_retries = max(0, int(max_retries))

    def set_forward_context_enabled(self, enabled: bool) -> None:
        self.forward_context_enabled = bool(enabled)

    def set_group_author_isolation_enabled(self, enabled: bool) -> None:
        self.group_author_isolation_enabled = bool(enabled)

    def set_continue_on_incomplete_enabled(self, enabled: bool) -> None:
        self.continue_on_incomplete_enabled = bool(enabled)

    def set_reaction_learning_enabled(self, enabled: bool) -> None:
        self.reaction_learning_enabled = bool(enabled)
        self.reaction_engine.set_enabled(enabled)

    def set_auto_reactions_enabled(self, enabled: bool) -> None:
        self.auto_reactions_enabled = bool(enabled)
        self.reaction_engine.set_auto_reactions_enabled(enabled)

    def set_guardrail(self, name: str, value: float) -> bool:
        normalized = str(name).strip().lower()
        if normalized == "reasoning_max_chars":
            self.router.local_reasoning_max_chars = max(200, int(value))
            return True
        if normalized == "stream_total_timeout_seconds":
            self.router.local_stream_total_timeout_seconds = max(5.0, float(value))
            return True
        if normalized == "stream_sock_read_timeout_seconds":
            self.router.local_stream_sock_read_timeout_seconds = max(2.0, float(value))
            return True
        if normalized == "include_reasoning":
            self.router.local_include_reasoning = bool(int(value))
            return True
        return False

    def set_context_snapshot(self, chat_id: int, payload: dict) -> None:
        self.last_context_snapshot[str(chat_id)] = dict(payload)

    def get_context_snapshot(self, chat_id: int) -> dict:
        return dict(self.last_context_snapshot.get(str(chat_id), {}))

    def get_context_snapshots(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ snapshot-—ã –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ø–æ —á–∞—Ç–∞–º."""
        return {str(chat_id): dict(payload) for chat_id, payload in self.last_context_snapshot.items()}

    def get_policy_snapshot(self) -> dict:
        return {
            "queue_enabled": bool(self.queue_enabled),
            "queue_notify_position_enabled": bool(self.queue_notify_position_enabled),
            "forward_context_enabled": bool(self.forward_context_enabled),
            "group_author_isolation_enabled": bool(self.group_author_isolation_enabled),
            "continue_on_incomplete_enabled": bool(self.continue_on_incomplete_enabled),
            "reaction_learning_enabled": bool(self.reaction_learning_enabled),
            "chat_mood_enabled": bool(self.chat_mood_enabled),
            "auto_reactions_enabled": bool(self.auto_reactions_enabled),
            "queue": self.queue_manager.get_stats(),
            "guardrails": {
                "local_include_reasoning": bool(self.router.local_include_reasoning),
                "local_reasoning_max_chars": int(self.router.local_reasoning_max_chars),
                "local_stream_total_timeout_seconds": float(self.router.local_stream_total_timeout_seconds),
                "local_stream_sock_read_timeout_seconds": float(self.router.local_stream_sock_read_timeout_seconds),
            },
        }


def _is_duplicate_message(chat_id: int, message_id: int) -> bool:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç True, –µ—Å–ª–∏ —ç—Ç–æ —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π update.
    –ù—É–∂–µ–Ω –¥–ª—è —Ä–µ–¥–∫–∏—Ö –¥—É–±–ª–µ–π –∞–ø–¥–µ–π—Ç–æ–≤ –ø–æ—Å–ª–µ reconnect.
    """
    now = time.time()
    # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤.
    stale_keys = [k for k, ts in _RECENT_MESSAGE_MARKERS.items() if (now - ts) > _RECENT_MESSAGE_TTL_SECONDS]
    for key in stale_keys:
        _RECENT_MESSAGE_MARKERS.pop(key, None)

    marker = f"{chat_id}:{message_id}"
    if marker in _RECENT_MESSAGE_MARKERS:
        return True
    _RECENT_MESSAGE_MARKERS[marker] = now
    return False


def _append_forward_to_burst_state(state: dict, message: Message, max_items: int) -> bool:
    """
    –î–æ–±–∞–≤–ª—è–µ—Ç –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ burst-–±—É—Ñ–µ—Ä –±–µ–∑ –¥—É–±–ª–µ–π.

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    - True: —Å–æ–æ–±—â–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª–µ–Ω–æ;
    - False: —ç—Ç–æ –¥—É–±–ª–∏–∫–∞—Ç (—Ç–æ—Ç –∂–µ chat_id + message_id), –±—É—Ñ–µ—Ä –Ω–µ –º–µ–Ω—è–ª—Å—è.
    """
    messages = list(state.get("messages") or [])
    chat_id = int(getattr(getattr(message, "chat", None), "id", 0) or 0)
    message_id = int(getattr(message, "id", 0) or 0)

    if chat_id and message_id:
        for item in messages:
            if int(getattr(getattr(item, "chat", None), "id", 0) or 0) != chat_id:
                continue
            if int(getattr(item, "id", 0) or 0) == message_id:
                return False

    messages.append(message)
    limit = int(max(2, max_items * 2))
    if len(messages) > limit:
        messages = messages[-limit:]
    state["messages"] = messages
    return True


def _is_self_private_message(message: Message) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –∏–∑ —ç—Ç–æ–≥–æ –∂–µ –∞–∫–∫–∞—É–Ω—Ç–∞
    –≤ –ø—Ä–∏–≤–∞—Ç–Ω—ã–π ¬´—á–∞—Ç —Å —Å–æ–±–æ–π¬ª (Saved Messages / self-dialog).
    """
    if not getattr(message, "from_user", None):
        return False
    if not bool(getattr(message.from_user, "is_self", False)):
        return False
    if getattr(message.chat, "type", None) != enums.ChatType.PRIVATE:
        return False
    return int(getattr(message.chat, "id", 0) or 0) == int(getattr(message.from_user, "id", 0) or 0)


def _sanitize_model_output(text: str, router=None) -> str:
    """–£–¥–∞–ª—è–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π –≤ Telegram."""
    if hasattr(router, "_sanitize_model_text"):
        try:
            candidate = router._sanitize_model_text(text)
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –º–æ–∫–æ–≤/–Ω–µ—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π:
            # –µ—Å–ª–∏ sanitize –≤–µ—Ä–Ω—É–ª –Ω–µ —Å—Ç—Ä–æ–∫—É, –æ—Ç–∫–∞—Ç—ã–≤–∞–µ–º—Å—è –∫ –ª–æ–∫–∞–ª—å–Ω–æ–π –æ—á–∏—Å—Ç–∫–µ.
            if isinstance(candidate, str):
                return candidate
        except Exception:
            pass
    if not text:
        return ""
    
    import re
    cleaned = str(text)
    # –£–¥–∞–ª—è–µ–º –≤—Å—ë –≤ —Ñ–æ—Ä–º–∞—Ç–µ <|...|>
    cleaned = re.sub(r"<\|.*?\|>", "", cleaned)
    # –£–¥–∞–ª—è–µ–º –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ —Ç–æ–∫–µ–Ω—ã
    for token in ("</s>", "<s>", "<br>"):
        cleaned = cleaned.replace(token, "")
    return cleaned.strip()


def _normalize_runtime_error_message_for_user(text: str, router=None) -> tuple[str, bool]:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç ¬´—Å—ã—Ä–æ–π¬ª runtime-error –º–æ–¥–µ–ª–∏ –≤ —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π –æ—Ç–≤–µ—Ç.

    –ó–∞—á–µ–º:
    –î–∞–∂–µ –µ—Å–ª–∏ –≤ –ø–∞–π–ø–ª–∞–π–Ω –ø—Ä–æ—Å–æ—á–∏–ª—Å—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –æ—Ç–≤–µ—Ç (–Ω–∞–ø—Ä–∏–º–µ—Ä, `Connection error.`),
    –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –¥–æ–ª–∂–µ–Ω –ø–æ–ª—É—á–∏—Ç—å –ø–æ–Ω—è—Ç–Ω—ã–π fallback, –∞ –Ω–µ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Ç–µ–∫—Å—Ç —à–ª—é–∑–∞.
    """
    raw = str(text or "").strip()
    if not raw:
        return "", False

    is_runtime_error = False
    detector = getattr(router, "_is_runtime_error_message", None)
    if callable(detector):
        try:
            detected = detector(raw)
            # –ó–∞—â–∏—Ç–∞ –æ—Ç –º–æ–∫–æ–≤: —É—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–π bool-–æ—Ç–≤–µ—Ç –¥–µ—Ç–µ–∫—Ç–æ—Ä–∞.
            if isinstance(detected, bool):
                is_runtime_error = detected
        except Exception:
            is_runtime_error = False

    lowered = raw.lower()
    if not is_runtime_error:
        fallback_markers = (
            "connection error",
            "network error",
            "failed to connect",
            "connection refused",
            "timeout",
            "timed out",
            "gateway timeout",
            "upstream",
            "provider unavailable",
            "no models loaded",
            "please load a model",
            "not_found",
            "not found",
            "quota exceeded",
            "billing",
            "out of credits",
            "permission_denied",
            "api key was reported as leaked",
            "invalid api key",
            "incorrect api key",
            "generative language api has not been used",
            "api has not been used in project",
            "it is disabled",
            "enable it by visiting",
        )
        is_runtime_error = any(marker in lowered for marker in fallback_markers)

    if not is_runtime_error:
        return raw, False

    detail = "–≤—Ä–µ–º–µ–Ω–Ω—ã–π —Å–±–æ–π –∫–∞–Ω–∞–ª–∞ AI"
    if "no models loaded" in lowered or "please load a model" in lowered:
        detail = "–ª–æ–∫–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞"
    elif "quota" in lowered or "billing" in lowered or "out of credits" in lowered:
        detail = "–ª–∏–º–∏—Ç –æ–±–ª–∞—á–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –∏—Å—á–µ—Ä–ø–∞–Ω"
    elif (
        "generative language api has not been used" in lowered
        or "api has not been used in project" in lowered
        or "it is disabled" in lowered
        or "enable it by visiting" in lowered
    ):
        detail = "–≤ Google Cloud –Ω–µ –≤–∫–ª—é—á—ë–Ω Generative Language API –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–ª—é—á–∞"
    elif "permission_denied" in lowered:
        detail = "–¥–æ—Å—Ç—É–ø –∫ –æ–±–ª–∞—á–Ω–æ–º—É –ø—Ä–æ–≤–∞–π–¥–µ—Ä—É –æ—Ç–∫–ª–æ–Ω—ë–Ω (permission denied)"
    elif (
        "api key was reported as leaked" in lowered
        or "invalid api key" in lowered
        or "incorrect api key" in lowered
    ):
        detail = "API –∫–ª—é—á –æ–±–ª–∞—á–Ω–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω –∏–ª–∏ —Å–∫–æ–º–ø—Ä–æ–º–µ—Ç–∏—Ä–æ–≤–∞–Ω"
    elif "not_found" in lowered or "not found" in lowered:
        detail = "–∑–∞–ø—Ä–æ—à–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞ —É –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"
    elif "timeout" in lowered or "timed out" in lowered:
        detail = "–ø—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞"
    elif (
        "connection error" in lowered
        or "network error" in lowered
        or "failed to connect" in lowered
        or "connection refused" in lowered
        or "upstream" in lowered
    ):
        detail = "–æ—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å AI-—à–ª—é–∑–æ–º"

    user_text = f"‚ö†Ô∏è –í—Ä–µ–º–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ AI: {detail}. –ü–æ–≤—Ç–æ—Ä–∏ –∑–∞–ø—Ä–æ—Å —á–µ—Ä–µ–∑ 3-5 —Å–µ–∫—É–Ω–¥."
    return user_text, True


def _is_explicit_non_russian_request(text: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –ø—Ä–æ—Å–∏–ª –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –æ—Ç–≤–µ—á–∞—Ç—å –Ω–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
    –ù—É–∂–µ–Ω, —á—Ç–æ–±—ã –Ω–µ —Ñ–æ—Ä—Å–∏—Ä–æ–≤–∞—Ç—å —Ä—É—Å—Å–∫–∏–π —Ç–∞–º, –≥–¥–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Ö–æ—á–µ—Ç –¥—Ä—É–≥–æ–π —è–∑—ã–∫.
    """
    payload = str(text or "").strip().lower()
    if not payload:
        return False
    markers = (
        "–Ω–∞ –∞–Ω–≥–ª–∏–π",
        "–ø–æ-–∞–Ω–≥–ª–∏–π",
        "in english",
        "answer in english",
        "speak english",
        "write in english",
        "–Ω–∞ –∏—Å–ø–∞–Ω",
        "–Ω–∞ —Ñ—Ä–∞–Ω—Ü—É–∑",
        "–Ω–∞ –Ω–µ–º–µ—Ü",
        "–Ω–∞ –∏—Ç–∞–ª—å—è–Ω",
        "–Ω–∞ –ø–æ—Ä—Ç—É–≥–∞–ª",
        "–Ω–∞ —Ç—É—Ä–µ—Ü",
        "–Ω–∞ –∫–∏—Ç–∞–π",
        "–Ω–∞ —è–ø–æ–Ω",
        "–Ω–∞ –∫–æ—Ä–µ–π",
    )
    return any(marker in payload for marker in markers)


def _should_force_russian_reply(
    user_text: str,
    is_private: bool,
    is_owner_sender: bool,
    is_voice_response_needed: bool,
) -> bool:
    """
    –†–µ—à–∞–µ—Ç, –≤–∫–ª—é—á–∞—Ç—å –ª–∏ —Å—Ç—Ä–æ–≥–∏–π —Ä—É—Å—Å–∫–∏–π guardrail –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞.
    """
    if _is_explicit_non_russian_request(user_text):
        return False
    if is_voice_response_needed:
        return True
    if is_owner_sender:
        return True
    return bool(is_private)


def _build_reply_context(message: Message) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç reply-–∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è prompt, –µ—Å–ª–∏ —Å–æ–æ–±—â–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –æ—Ç–≤–µ—Ç–æ–º."""
    if not getattr(message, "reply_to_message", None):
        return ""
    reply_author = "Unknown"
    reply_from = getattr(message.reply_to_message, "from_user", None)
    if reply_from:
        reply_author = (
            f"@{reply_from.username}"
            if getattr(reply_from, "username", None)
            else (getattr(reply_from, "first_name", None) or "User")
        )
    reply_text = _message_content_hint(message.reply_to_message)
    if not reply_text:
        return ""
    return f"[REPLY CONTEXT from {reply_author}]: {reply_text}"


def _build_forward_context(message: Message, enabled: bool = True) -> str:
    """–§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ñ–æ—Ä–≤–∞—Ä–¥–∞, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ —Å—á–∏—Ç–∞–ª–∞ —ç—Ç–æ –ø–æ–∑–∏—Ü–∏–µ–π –≤–ª–∞–¥–µ–ª—å—Ü–∞."""
    if not enabled:
        return ""

    chat_id = int(getattr(getattr(message, "chat", None), "id", 0) or 0)
    message_id = int(getattr(message, "id", 0) or 0)
    burst_key = f"{chat_id}:{message_id}"
    burst_context = _FORWARD_BURST_CONTEXT_MAP.pop(burst_key, "")

    forwarded_from = None
    if getattr(message, "forward_from", None):
        fwd_user = message.forward_from
        forwarded_from = (
            f"@{fwd_user.username}"
            if getattr(fwd_user, "username", None)
            else (getattr(fwd_user, "first_name", None) or "unknown_user")
        )
    if not forwarded_from and getattr(message, "forward_sender_name", None):
        forwarded_from = str(message.forward_sender_name)
    if not forwarded_from and getattr(message, "forward_from_chat", None):
        fwd_chat = message.forward_from_chat
        forwarded_from = (
            getattr(fwd_chat, "title", None)
            or getattr(fwd_chat, "username", None)
            or "unknown_chat"
        )
    if not forwarded_from:
        return burst_context

    fwd_date = getattr(message, "forward_date", None)
    fwd_date_text = str(fwd_date) if fwd_date else "n/a"
    auto_fwd = bool(getattr(message, "is_automatic_forward", False))
    base_context = (
        "[FORWARDED CONTEXT]: —ç—Ç–æ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã–π –º–∞—Ç–µ—Ä–∏–∞–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, "
        "–Ω–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–π –µ–≥–æ –∫–∞–∫ –ø–æ–∑–∏—Ü–∏—é –≤–ª–∞–¥–µ–ª—å—Ü–∞.\n"
        f"–ò—Å—Ç–æ—á–Ω–∏–∫: {forwarded_from}\n"
        f"–î–∞—Ç–∞ —Ñ–æ—Ä–≤–∞—Ä–¥–∞: {fwd_date_text}\n"
        f"–ê–≤—Ç–æ—Ñ–æ—Ä–≤–∞—Ä–¥: {auto_fwd}"
    )
    if burst_context:
        return f"{base_context}\n\n{burst_context}"
    return base_context


def _is_forwarded_message(message: Message) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —è–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã–º (–ª—é–±–æ–π —Ç–∏–ø —Ñ–æ—Ä–≤–∞—Ä–¥–∞).
    """
    return bool(
        getattr(message, "forward_date", None)
        or getattr(message, "forward_from", None)
        or getattr(message, "forward_sender_name", None)
        or getattr(message, "forward_from_chat", None)
        or getattr(message, "forward_from_message_id", None)
    )


def _compose_forward_burst_context(messages: list[Message], max_items: int = 8) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç ¬´–ø–∞—á–∫–∏ —Ñ–æ—Ä–≤–∞—Ä–¥–æ–≤¬ª, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –≤–∏–¥–µ–ª–∞ —Å–≤—è–∑–Ω–æ—Å—Ç—å
    –∏ –Ω–µ –æ—Ç–≤–µ—á–∞–ª–∞ –Ω–∞ –∫–∞–∂–¥–æ–µ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç–¥–µ–ª—å–Ω–æ.
    """
    if not messages:
        return ""
    safe_max = max(1, int(max_items))
    tail = messages[-safe_max:]
    lines: list[str] = []
    for idx, msg in enumerate(tail, start=1):
        source = "unknown_source"
        if getattr(msg, "forward_from", None):
            fwd_user = msg.forward_from
            source = (
                f"@{fwd_user.username}"
                if getattr(fwd_user, "username", None)
                else (getattr(fwd_user, "first_name", None) or "unknown_user")
            )
        elif getattr(msg, "forward_sender_name", None):
            source = str(msg.forward_sender_name)
        elif getattr(msg, "forward_from_chat", None):
            fwd_chat = msg.forward_from_chat
            source = (
                getattr(fwd_chat, "title", None)
                or getattr(fwd_chat, "username", None)
                or "unknown_chat"
            )
        payload = _message_content_hint(msg)
        if not payload:
            payload = "[empty]"
        lines.append(f"{idx}. [{source}] {payload}")
    return (
        "[FORWARDED BATCH CONTEXT]: —ç—Ç–æ —á–∞—Å—Ç—å –æ–¥–Ω–æ–π –ø–∞—á–∫–∏ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π. "
        "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏—Ö –∫–∞–∫ –µ–¥–∏–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç:\n"
        + "\n".join(lines)
    )


def _build_author_context(message: Message, is_owner_sender: bool) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –∞–≤—Ç–æ—Ä—Å—Ç–≤–∞ —Ç–µ–∫—É—â–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–æ–≤.
    –ü–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –Ω–µ –ø—É—Ç–∞—Ç—å –≤–ª–∞–¥–µ–ª—å—Ü–∞ —Å –¥—Ä—É–≥–∏–º–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏.
    """
    user = getattr(message, "from_user", None)
    username = ""
    display_name = "unknown_user"
    user_id = 0
    if user:
        username = str(getattr(user, "username", "") or "").strip()
        display_name = str(getattr(user, "first_name", "") or "").strip() or "unknown_user"
        user_id = int(getattr(user, "id", 0) or 0)

    author = f"@{username}" if username else display_name
    raw_chat_type = getattr(getattr(message, "chat", None), "type", "unknown")
    if hasattr(raw_chat_type, "name"):
        chat_type = str(getattr(raw_chat_type, "name", "unknown")).lower()
    else:
        chat_type = str(raw_chat_type).lower()

    owner_marker = "owner" if is_owner_sender else "participant"
    return (
        "[AUTHOR CONTEXT]:\n"
        f"author={author}\n"
        f"author_id={user_id}\n"
        f"author_role={owner_marker}\n"
        f"chat_type={chat_type}\n"
        f"–¶–µ–ª–µ–≤–æ–π –ø–æ–ª—É—á–∞—Ç–µ–ª—å –æ—Ç–≤–µ—Ç–∞: {author} (author_id={user_id}).\n"
        "–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ —Ç–µ–∫—É—â–µ–º—É author. –ù–µ –ø–æ–¥–º–µ–Ω—è–π –∞–≤—Ç–æ—Ä–∞ –≤–ª–∞–¥–µ–ª—å—Ü–µ–º, –µ—Å–ª–∏ author_role=participant.\n"
        "–ï—Å–ª–∏ –≤ [REPLY CONTEXT] —Ü–∏—Ç–∏—Ä—É–µ—Ç—Å—è –¥—Ä—É–≥–æ–π —á–µ–ª–æ–≤–µ–∫, —ç—Ç–æ –º–∞—Ç–µ—Ä–∏–∞–ª –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, –∞ –Ω–µ –Ω–æ–≤—ã–π author.\n"
        "–ë–ª–æ–∫–∏ [REPLY CONTEXT] –∏ [FORWARDED CONTEXT] —è–≤–ª—è—é—Ç—Å—è —Ü–∏—Ç–∞—Ç–æ–π/–º–∞—Ç–µ—Ä–∏–∞–ª–æ–º –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞, "
        "–∞ –Ω–µ –Ω–∞–º–µ—Ä–µ–Ω–∏–µ–º —Ç–µ–∫—É—â–µ–≥–æ author."
    )


def _build_user_memory_payload(
    message: Message,
    sender: str,
    text: str,
    is_owner_sender: bool,
) -> dict:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç –µ–¥–∏–Ω—ã–π payload –¥–ª—è –∑–∞–ø–∏—Å–∏ user-—Å–æ–æ–±—â–µ–Ω–∏—è –≤ –ø–∞–º—è—Ç—å.
    –ù—É–∂–µ–Ω, —á—Ç–æ–±—ã –∏ –æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ, –∏ –Ω–µ–æ—Ç–≤–µ—á–µ–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–º–µ–ª–∏ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –ø–æ–ª—è –∞–≤—Ç–æ—Ä–∞.
    """
    chat_type_value = str(getattr(getattr(message.chat, "type", None), "name", message.chat.type)).lower()
    user_id = int(getattr(getattr(message, "from_user", None), "id", 0) or 0)
    return {
        "role": "user",
        "user": sender,
        "text": str(text or ""),
        "author_id": user_id,
        "author_username": str(sender or ""),
        "author_role": "owner" if is_owner_sender else "participant",
        "chat_type": chat_type_value,
    }


def _is_voice_reply_requested(text: str) -> bool:
    """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –ø—Ä–æ—Å–∏—Ç –ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≥–æ–ª–æ—Å–æ–≤–æ–π –æ—Ç–≤–µ—Ç —Ç–µ–∫—Å—Ç–æ–º."""
    lowered = (text or "").strip().lower()
    if not lowered:
        return False
    triggers = (
        "–æ—Ç–≤–µ—Ç—å –≥–æ–ª–æ—Å–æ–º",
        "–≥–æ–ª–æ—Å–æ–º –æ—Ç–≤–µ—Ç—å",
        "—Å–∫–∞–∂–∏ –≥–æ–ª–æ—Å–æ–º",
        "–æ–∑–≤—É—á—å –æ—Ç–≤–µ—Ç",
        "–∑–∞–ø–∏—à–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ",
        "–ø—Ä–∏—à–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ",
        "–≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        "voice reply",
        "reply by voice",
        "respond with voice",
        "voice message",
        "send voice",
    )
    if any(token in lowered for token in triggers):
        return True

    # –õ–æ–≤–∏–º –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –≤—Ä–æ–¥–µ:
    # "–û—Ç–≤–µ—á–∞–π, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, –≥–æ–ª–æ—Å–æ–º" / "–û—Ç–≤–µ—Ç—å –º–Ω–µ –≥–æ–ª–æ—Å–æ–º".
    russian_patterns = (
        r"\b–æ—Ç–≤–µ—á(?:–∞–π|–∞–π—Ç–µ|–∞–π-–∫–∞|–∞–π—Ç–µ-–∫–∞)\b.{0,40}\b–≥–æ–ª–æ—Å(?:–æ–º|–æ–≤–æ–π|–æ–≤–æ–µ)?\b",
        r"\b–æ—Ç–≤–µ—Ç(?:—å|—å—Ç–µ)\b.{0,40}\b–≥–æ–ª–æ—Å(?:–æ–º|–æ–≤–æ–π|–æ–≤–æ–µ)?\b",
        r"\b–≥–æ–ª–æ—Å(?:–æ–º|–æ–≤–æ–π|–æ–≤–æ–µ)?\b.{0,40}\b–æ—Ç–≤–µ—á(?:–∞–π|–∞–π—Ç–µ|–∞–π-–∫–∞|–∞–π—Ç–µ-–∫–∞|—É|–∞—Ç—å)\b",
    )
    return any(re.search(pattern, lowered) for pattern in russian_patterns)


def _extract_code_prompt_flags(message_text: str) -> tuple[str, bool, bool]:
    """
    –†–∞–∑–±–∏—Ä–∞–µ—Ç !code –∫–æ–º–∞–Ω–¥—É –∏ –≤—ã–¥–µ–ª—è–µ—Ç:
    - prompt
    - confirm_expensive
    - raw_code_mode (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω --raw-code)
    """
    raw = message_text or ""
    try:
        argv = shlex.split(raw)
    except ValueError:
        argv = raw.split()

    if len(argv) < 2:
        return "", False, False

    confirm_expensive = False
    raw_code_mode = False
    payload_tokens: list[str] = []
    for token in argv[1:]:
        normalized = token.strip().lower()
        if normalized in {"--confirm-expensive", "--confirm", "confirm"}:
            confirm_expensive = True
            continue
        if normalized in {"--raw-code", "--raw"}:
            raw_code_mode = True
            continue
        payload_tokens.append(token)

    prompt = " ".join(payload_tokens).strip()
    return prompt, confirm_expensive, raw_code_mode


def _is_critical_code_request(prompt: str) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö coding-–∑–∞–¥–∞—á:
    –¥–µ–ø–ª–æ–π, –ø—Ä–æ–¥, –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å, –ø–ª–∞—Ç–µ–∂–∏, –º–∏–≥—Ä–∞—Ü–∏–∏ –∏ —Ç.–ø.
    """
    text = (prompt or "").lower()
    markers = (
        "prod", "production", "–¥–µ–ø–ª–æ–π", "—Ä–µ–ª–∏–∑", "security", "–±–µ–∑–æ–ø–∞—Å",
        "auth", "oauth", "jwt", "billing", "–ø–ª–∞—Ç–µ–∂", "migration", "–º–∏–≥—Ä–∞—Ü",
        "db", "database", "postgres", "rollback", "infra", "k8s", "kubernetes",
    )
    return any(marker in text for marker in markers)


def _build_safe_code_prompt(prompt: str, strict_mode: bool = False) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∑–∞–ø—Ä–æ—Å –¥–ª—è code-—Ä–µ–∂–∏–º–∞:
    1) –ü–ª–∞–Ω
    2) –ö–æ–¥
    3) –¢–µ—Å—Ç—ã
    4) –†–∏—Å–∫–∏
    """
    strict_clause = (
        "–†–µ–∂–∏–º strict: —É—á–∏—Ç—ã–≤–∞–π production-–æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è, –≤–∞–ª–∏–¥–∞—Ü–∏—é –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, "
        "–æ—à–∏–±–∫–∏/rollback –∏ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é.\n"
        if strict_mode else ""
    )
    return (
        "–¢—ã senior-–∏–Ω–∂–µ–Ω–µ—Ä. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.\n"
        f"{strict_clause}"
        "–í–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ:\n"
        "1) PLAN ‚Äî –∫—Ä–∞—Ç–∫–∏–π –ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω (3-7 –ø—É–Ω–∫—Ç–æ–≤)\n"
        "2) CODE ‚Äî –≥–æ—Ç–æ–≤—ã–π –∫–æ–¥ (fenced block)\n"
        "3) TESTS ‚Äî –º–∏–Ω–∏–º–∞–ª—å–Ω–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω—ã–µ —Ç–µ—Å—Ç—ã/–ø—Ä–æ–≤–µ—Ä–∫–∏\n"
        "4) RISKS ‚Äî –∫–æ—Ä–æ—Ç–∫–∏–π —Å–ø–∏—Å–æ–∫ —Ä–∏—Å–∫–æ–≤ –∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π\n\n"
        f"–ó–∞–¥–∞—á–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:\n{prompt}"
    )


def _to_plain_stream_text(text: str) -> str:
    """
    –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ markdown –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ–≥–æ plain-text edit.
    –ù—É–∂–Ω–∞ –∫–∞–∫ fallback, –µ—Å–ª–∏ Telegram –æ—Ç–≤–µ—Ä–≥–∞–µ—Ç markdown-–ø–∞—Ä—Å–∏–Ω–≥ –≤ —Å—Ç—Ä–∏–º–µ.
    """
    if not text:
        return "..."

    plain = str(text)
    replacements = {
        "```": "",
        "`": "",
        "**": "",
        "__": "",
        "~~": "",
    }
    for source, target in replacements.items():
        plain = plain.replace(source, target)
    return plain.strip() or "..."


def _prepare_tts_text(text: str) -> str:
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏:
    - —É–±–∏—Ä–∞–µ—Ç —Å–ª—É–∂–µ–±–Ω—ã–µ/—Å—Ç–∞—Ç—É—Å–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏ –∏ markdown-–º—É—Å–æ—Ä,
    - —Ä–µ–∂–µ—Ç –º–µ—Ç–∞-–≤—Å—Ç–∞–≤–∫–∏ –≤ –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã—Ö —Å–∫–æ–±–∫–∞—Ö,
    - –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–æ–º–ø–∞–∫—Ç–Ω—ã–π, ¬´—á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–π¬ª —Ç–µ–∫—Å—Ç.
    """
    if not text:
        return ""

    cleaned = _to_plain_stream_text(text)
    cleaned = re.sub(r"\[[^\]]{1,160}\]", "", cleaned)

    skip_prefixes = (
        "—Å–≤—è–∑—å —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞",
        "—è –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ",
        "voice reply",
        "llm error",
        "–æ—à–∏–±–∫–∞",
        "status:",
        "system:",
    )
    lines = []
    for raw_line in cleaned.splitlines():
        line = raw_line.strip(" \t-‚Ä¢*")
        if not line:
            continue
        low = line.lower()
        if any(low.startswith(prefix) for prefix in skip_prefixes):
            continue
        lines.append(line)

    compact = "\n".join(lines).strip()
    compact = re.sub(r"\n{3,}", "\n\n", compact)
    return compact


def _split_tts_chunks(text: str, max_chars: int = 1100, max_chunks: int = 6) -> list[str]:
    """
    –î–µ–ª–∏—Ç –¥–ª–∏–Ω–Ω—ã–π TTS-—Ç–µ–∫—Å—Ç –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —á–∞—Å—Ç–∏ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è.

    –ü–æ—á–µ–º—É —Ç–∞–∫:
    - edge-tts –∏ Telegram —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–∞ —É–º–µ—Ä–µ–Ω–Ω–æ–π –¥–ª–∏–Ω–µ –≤—Ö–æ–¥–∞;
    - —Ä–∞–Ω—å—à–µ —Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–ª—Å—è –¥–æ ~1750 —Å–∏–º–≤–æ–ª–æ–≤ –∏ —Ö–≤–æ—Å—Ç —Ç–µ—Ä—è–ª—Å—è.
    –¢–µ–ø–µ—Ä—å –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ voice-—á–∞—Å—Ç–µ–π –ø–æ–¥—Ä—è–¥.
    """
    payload = str(text or "").strip()
    if not payload:
        return []

    safe_max_chars = max(300, int(max_chars))
    safe_max_chunks = max(1, int(max_chunks))

    paragraphs = [p.strip() for p in re.split(r"\n{2,}", payload) if p.strip()]
    if not paragraphs:
        paragraphs = [payload]

    chunks: list[str] = []
    current = ""

    def _flush() -> None:
        nonlocal current
        if current.strip():
            chunks.append(current.strip())
            current = ""

    for paragraph in paragraphs:
        candidate = f"{current}\n\n{paragraph}".strip() if current else paragraph
        if len(candidate) <= safe_max_chars:
            current = candidate
            continue

        _flush()
        if len(paragraph) <= safe_max_chars:
            current = paragraph
            continue

        # –û—á–µ–Ω—å –¥–ª–∏–Ω–Ω—ã–π –∞–±–∑–∞—Ü —Ä–µ–∂–µ–º –ø–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º/—Å–ª–æ–≤–∞–º.
        sentences = [s.strip() for s in re.split(r"(?<=[.!?‚Ä¶])\s+", paragraph) if s.strip()]
        if not sentences:
            sentences = [paragraph]

        for sentence in sentences:
            candidate_sentence = f"{current} {sentence}".strip() if current else sentence
            if len(candidate_sentence) <= safe_max_chars:
                current = candidate_sentence
                continue

            _flush()
            if len(sentence) <= safe_max_chars:
                current = sentence
                continue

            # Fallback: —Ä—É–±–∏–º –ø–æ —Å–ª–æ–≤–∞–º, –µ—Å–ª–∏ –¥–∞–∂–µ –æ–¥–Ω–æ "–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ" —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ.
            words = sentence.split()
            for word in words:
                candidate_word = f"{current} {word}".strip() if current else word
                if len(candidate_word) <= safe_max_chars:
                    current = candidate_word
                else:
                    _flush()
                    current = word
            _flush()

    _flush()

    if len(chunks) <= safe_max_chunks:
        return chunks

    # –°—Ö–ª–æ–ø—ã–≤–∞–µ–º —Ö–≤–æ—Å—Ç –≤ –ø–æ—Å–ª–µ–¥–Ω—é—é —á–∞—Å—Ç—å, —á—Ç–æ–±—ã –Ω–µ —Å–ø–∞–º–∏—Ç—å –¥–µ—Å—è—Ç–∫–∞–º–∏ voice-—Å–æ–æ–±—â–µ–Ω–∏–π.
    head = chunks[: safe_max_chunks - 1]
    tail = " ".join(chunks[safe_max_chunks - 1 :]).strip()
    if tail:
        head.append(tail)
    return [part for part in head if part]


def _collapse_repeated_paragraphs(text: str, max_consecutive_repeats: int = 2) -> tuple[str, bool]:
    """
    –°—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ –∞–±–∑–∞—Ü—ã.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–æ—á–∏—â–µ–Ω–Ω—ã–π_—Ç–µ–∫—Å—Ç, –±—ã–ª–∏_–ª–∏_—É–¥–∞–ª–µ–Ω–∏—è).
    """
    if not text:
        return "", False
    paragraphs = re.split(r"\n{2,}", str(text))
    output: list[str] = []
    removed = False
    last_norm = ""
    last_count = 0

    for paragraph in paragraphs:
        cleaned = paragraph.strip()
        if not cleaned:
            continue
        normalized = re.sub(r"\s+", " ", cleaned).strip().lower()
        normalized = re.sub(r"[\"'`*_~]+", "", normalized)
        normalized = re.sub(r"[^\w\s]+", " ", normalized, flags=re.UNICODE)
        normalized = re.sub(r"\s+", " ", normalized).strip()
        if normalized == last_norm:
            last_count += 1
        else:
            last_norm = normalized
            last_count = 1
        if last_count <= max_consecutive_repeats:
            output.append(cleaned)
        else:
            removed = True
    return ("\n\n".join(output).strip(), removed)


def _collapse_repeated_lines(text: str, max_consecutive_repeats: int = 2) -> tuple[str, bool]:
    """
    –°—Ö–ª–æ–ø—ã–≤–∞–µ—Ç –ø–æ–¥—Ä—è–¥ –∏–¥—É—â–∏–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Å—Ç—Ä–æ–∫–∏ (—Å –º—è–≥–∫–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π),
    —á—Ç–æ–±—ã –≥–∞—Å–∏—Ç—å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏–µ –≤ –æ–±—ã—á–Ω–æ–º –∞–±–∑–∞—Ü–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –±–µ–∑ –ø—É—Å—Ç—ã—Ö —Å—Ç—Ä–æ–∫.
    """
    if not text:
        return "", False

    lines = str(text).splitlines()
    output: list[str] = []
    removed = False
    last_norm = ""
    last_count = 0

    for raw in lines:
        line = str(raw or "")
        if not line.strip():
            output.append(line)
            last_norm = ""
            last_count = 0
            continue
        normalized = line.strip().lower()
        normalized = re.sub(r"[\"'`*_~]+", "", normalized)
        normalized = re.sub(r"[^\w\s]+", " ", normalized, flags=re.UNICODE)
        normalized = re.sub(r"\s+", " ", normalized)
        if normalized == last_norm:
            last_count += 1
        else:
            last_norm = normalized
            last_count = 1
        if last_count <= max_consecutive_repeats:
            output.append(line)
        else:
            removed = True

    payload = "\n".join(output).strip()
    payload = re.sub(r"\n{3,}", "\n\n", payload)
    return payload, removed


def _dedupe_repeated_long_paragraphs(
    text: str,
    min_normalized_len: int = 140,
    max_occurrences: int = 1,
) -> tuple[str, bool]:
    """
    –£–±–∏—Ä–∞–µ—Ç ¬´—Å–∫–ª–µ–µ–Ω–Ω—ã–µ¬ª –¥–ª–∏–Ω–Ω—ã–µ –¥—É–±–ª–∏ –∞–±–∑–∞—Ü–µ–≤ –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ –ø–æ–¥—Ä—è–¥.
    –ù—É–∂–µ–Ω –¥–ª—è –∫–µ–π—Å–æ–≤, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –ø–æ–≤—Ç–æ—Ä—è–µ—Ç –±–æ–ª—å—à–æ–π –±–ª–æ–∫ —á–µ—Ä–µ–∑ 1-2 –≤—Å—Ç–∞–≤–∫–∏.
    """
    if not text:
        return "", False

    paragraphs = [p.strip() for p in re.split(r"\n{2,}", str(text)) if p.strip()]
    if not paragraphs:
        return str(text).strip(), False

    seen_counts: dict[str, int] = {}
    output: list[str] = []
    removed = False
    safe_max_occurrences = max(1, int(max_occurrences))

    for paragraph in paragraphs:
        normalized = re.sub(r"\s+", " ", paragraph).strip().lower()
        normalized = re.sub(r"[\"'`*_~]+", "", normalized)
        normalized = re.sub(r"[^\w\s]+", " ", normalized, flags=re.UNICODE)
        normalized = re.sub(r"\s+", " ", normalized).strip()
        if len(normalized) < max(20, int(min_normalized_len)):
            output.append(paragraph)
            continue

        count = seen_counts.get(normalized, 0) + 1
        seen_counts[normalized] = count
        if count <= safe_max_occurrences:
            output.append(paragraph)
        else:
            removed = True

    return "\n\n".join(output).strip(), removed


def _build_vision_route_fact_line(meta: dict) -> str:
    """
    –§–æ—Ä–º–∏—Ä—É–µ—Ç —á–µ–ª–æ–≤–µ–∫–æ—á–∏—Ç–∞–µ–º—ã–π —Ñ–∞–∫—Ç –æ —Ä–µ–∞–ª—å–Ω–æ–º –º–∞—Ä—à—Ä—É—Ç–µ vision.
    –≠—Ç–∞ —Å—Ç—Ä–æ–∫–∞ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫–æ–¥–æ–º (–Ω–µ –º–æ–¥–µ–ª—å—é), —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å ¬´–≤—ã–∫—Ä—É—á–∏–≤–∞–Ω–∏–µ¬ª.
    """
    if not isinstance(meta, dict):
        return ""

    route = str(meta.get("route") or "").strip().lower()
    model = str(meta.get("model") or "").strip()
    fallback_used = bool(meta.get("fallback_used"))
    error = str(meta.get("error") or "").strip()

    if route == "local_lm_studio":
        return f"‚ÑπÔ∏è –§–∞–∫—Ç vision: –ª–æ–∫–∞–ª—å–Ω–æ —á–µ—Ä–µ–∑ LM Studio (`{model or '-'}`)."
    if route == "cloud_gemini":
        if fallback_used:
            return (
                f"‚ÑπÔ∏è –§–∞–∫—Ç vision: cloud —á–µ—Ä–µ–∑ Gemini (`{model or '-'}`), "
                "–ø–æ—Å–ª–µ –Ω–µ—É—Å–ø–µ—à–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ vision."
            )
        return f"‚ÑπÔ∏è –§–∞–∫—Ç vision: cloud —á–µ—Ä–µ–∑ Gemini (`{model or '-'}`)."
    if route == "error":
        return f"‚ÑπÔ∏è –§–∞–∫—Ç vision: –æ—à–∏–±–∫–∞ vision-–∫–æ–Ω—Ç—É—Ä–∞ (`{error or 'unknown_error'}`)."
    return ""


def _enforce_vision_route_consistency(text: str, vision_meta: dict) -> tuple[str, bool]:
    """
    –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç –Ω–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—Ç —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–º—É –º–∞—Ä—à—Ä—É—Ç—É vision.
    –ï—Å–ª–∏ –º–∞—Ä—à—Ä—É—Ç cloud, —É–¥–∞–ª—è–µ–º –ª–æ–∂–Ω—ã–µ –±–ª–æ–∫–∏ "–ø–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–æ" –∏ –¥–æ–±–∞–≤–ª—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∫—É.
    """
    payload = str(text or "").strip()
    if not payload:
        return "", False
    if not isinstance(vision_meta, dict):
        return payload, False

    route = str(vision_meta.get("route") or "").strip().lower()
    if route != "cloud_gemini":
        return payload, False

    contradiction_patterns = (
        r"–ø–æ–ª–Ω–æ—Å—Ç—å—é\s+–ø–µ—Ä–µ—à–ª–∏\s+–∫\s+–ª–æ–∫–∞–ª—å–Ω",
        r"–≤—Å–µ\s+–æ–ø–µ—Ä–∞—Ü–∏–∏.*–ª–æ–∫–∞–ª—å–Ω",
        r"–≤—Å–µ–≥–¥–∞\s+–ª–æ–∫–∞–ª—å–Ω",
        r"–ø–æ–ª–Ω–æ—Å—Ç—å—é\s+–æ—Ç–∫–∞–∑–∞–ª–∏—Å—å\s+–æ—Ç\s+–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è\s+–≤–Ω–µ—à–Ω–∏—Ö\s+–æ–±–ª–∞—á–Ω—ã—Ö",
        r"–Ω–∏–∫–∞–∫–∏–µ.*–Ω–µ\s+–ø–µ—Ä–µ–¥–∞[–µ—é]—Ç[—Åc]—è?\s+–≤\s+–∏–Ω—Ç–µ—Ä–Ω–µ—Ç",
    )

    paragraphs = [p.strip() for p in re.split(r"\n{2,}", payload) if p.strip()]
    if not paragraphs:
        return payload, False

    kept: list[str] = []
    removed = False
    for paragraph in paragraphs:
        normalized = re.sub(r"\s+", " ", paragraph).strip().lower()
        if any(re.search(pattern, normalized) for pattern in contradiction_patterns):
            removed = True
            continue
        kept.append(paragraph)

    if not kept:
        kept = [payload]
    cleaned = "\n\n".join(kept).strip()

    model = str(vision_meta.get("model") or "-").strip()
    correction = (
        f"‚ö†Ô∏è –ö–æ—Ä—Ä–µ–∫—Ü–∏—è —Ñ–∞–∫—Ç–∞: —ç—Ç–æ—Ç vision-–∑–∞–ø—Ä–æ—Å –≤—ã–ø–æ–ª–Ω–µ–Ω —á–µ—Ä–µ–∑ cloud (`{model}`), "
        "–ø–æ—ç—Ç–æ–º—É —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –ø—Ä–æ ¬´–ø–æ–ª–Ω–æ—Å—Ç—å—é –ª–æ–∫–∞–ª—å–Ω–æ¬ª –¥–ª—è —ç—Ç–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–µ–ø—Ä–∏–º–µ–Ω–∏–º—ã."
    )
    if correction not in cleaned:
        cleaned = f"{correction}\n\n{cleaned}".strip()
    return cleaned, removed


def _cap_numbered_list_items(text: str, max_items: int = 20) -> tuple[str, bool]:
    """
    –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–µ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ø–∏—Å–∫–∏.
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç: (–æ—á–∏—â–µ–Ω–Ω—ã–π_—Ç–µ–∫—Å—Ç, –±—ã–ª_–ª–∏_trim).
    """
    if not text or max_items <= 0:
        return text or "", False

    lines = str(text).splitlines()
    result: list[str] = []
    numbered_count = 0
    trimmed = False
    pattern = re.compile(r"^\s*\d+[\.\)]\s+")

    for line in lines:
        if pattern.match(line):
            numbered_count += 1
            if numbered_count > max_items:
                trimmed = True
                continue
        result.append(line)

    if trimmed:
        result.append("")
        result.append(
            f"‚ö†Ô∏è –°–ø–∏—Å–æ–∫ –±—ã–ª –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –¥–æ {max_items} –ø—É–Ω–∫—Ç–æ–≤, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è –æ—Ç–≤–µ—Ç–∞."
        )
    return ("\n".join(result).strip(), trimmed)


def _prune_repetitive_numbered_items(
    text: str,
    max_same_body: int = 2,
) -> tuple[str, bool]:
    """
    –£–±–∏—Ä–∞–µ—Ç –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è –ø—É–Ω–∫—Ç—ã –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º —Ç–µ–∫—Å—Ç–æ–º –ø—É–Ω–∫—Ç–∞.

    –ü—Ä–∏–º–µ—Ä:
    - "31. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª—é–±—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è —ç–≤–∞–∫—É–∞—Ü–∏–∏"
    - "36. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –ª—é–±—É—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –¥–ª—è —ç–≤–∞–∫—É–∞—Ü–∏–∏"

    –í—Ç–æ—Ä–æ–π –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏–µ –¥—É–±–ª–∏ —É–¥–∞–ª—è—é—Ç—Å—è.
    """
    if not text:
        return "", False

    lines = str(text).splitlines()
    numbered_pattern = re.compile(r"^\s*(\d+[\.\)])\s+(.*\S)\s*$")
    body_seen: dict[str, int] = {}
    cleaned_lines: list[str] = []
    removed = False

    for line in lines:
        match = numbered_pattern.match(line)
        if not match:
            cleaned_lines.append(line)
            continue

        body = match.group(2).strip().lower()
        body = re.sub(r"\s+", " ", body)
        body = re.sub(r"[\"'`*_~]+", "", body)
        count = int(body_seen.get(body, 0)) + 1
        body_seen[body] = count
        if count > max_same_body:
            removed = True
            continue
        cleaned_lines.append(line)

    return ("\n".join(cleaned_lines).strip(), removed)


def _drop_service_busy_phrases(text: str) -> tuple[str, bool]:
    """
    –£–¥–∞–ª—è–µ—Ç –∏–∑ –æ—Ç–≤–µ—Ç–∞ —Å–ª—É–∂–µ–±–Ω—ã–µ ¬´–æ—á–µ—Ä–µ–¥–Ω—ã–µ¬ª –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ñ—Ä–∞–∑—ã,
    –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–ø–∞–¥–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é.
    """
    if not text:
        return "", False

    blocked_patterns = (
        "–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∑–∞–ø—Ä–æ—Å",
        "–æ—Ç–ø—Ä–∞–≤—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥",
        "–ø–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –∏ –ø–æ–≤—Ç–æ—Ä–∏",
        "–¥–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏",
        "–ø–æ–∑–∏—Ü–∏—è:",
    )

    output_lines: list[str] = []
    removed = False
    for line in str(text).splitlines():
        low = line.strip().lower()
        if any(pattern in low for pattern in blocked_patterns):
            removed = True
            continue
        output_lines.append(line)

    normalized = "\n".join(output_lines).strip()
    normalized = re.sub(r"\n{3,}", "\n\n", normalized)
    return normalized, removed


def _drop_tool_artifact_blocks(text: str) -> tuple[str, bool]:
    """
    –£–¥–∞–ª—è–µ—Ç —É—Ç–µ—á–∫–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ tool/scaffold –≤—ã–≤–æ–¥–∞ –º–æ–¥–µ–ª–∏:
    - begin/end_of_box, NO_REPLY, HEARTBEAT_OK
    - JSON-—Å—Ö–µ–º—ã sessions_send/action/parameters
    - –¥–∞–º–ø—ã AGENTS.md –∏ –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –±–ª–æ–∫–∏ Default Channel.
    """
    payload = str(text or "").strip()
    if not payload:
        return "", False

    original = payload
    # –£–¥–∞–ª—è–µ–º –º–∞—Ä–∫–µ—Ä—ã box, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –ø–æ–ª–µ–∑–Ω—ã–π —Ç–µ–∫—Å—Ç.
    payload = payload.replace("<|begin_of_box|>", "")
    payload = payload.replace("<|end_of_box|>", "")

    blocked_fragments = (
        "begin_of_box",
        "end_of_box",
        "no_reply",
        "heartbeat_ok",
        "i will now call the",
        "memory_get",
        "memory_search",
        "sessions_spawn",
        "sessions_send",
        "\"action\": \"sessions_send\"",
        "\"action\":\"sessions_send\"",
        "\"sessionkey\"",
        "\"default channel",
        "default channel id",
        "## /users/",
        "# agents.md - workspace agents",
        "## agent list",
        "### default agents",
        "</tool_call>",
    )
    noisy_line_patterns = (
        r"^\s*\"?(name|description|icon|color|sound|volume|timeout|type|id)\"?\s*:\s*\"?whatsapp\"?",
        r"^\s*-\s*\"default channel",
    )

    filtered_lines: list[str] = []
    removed = False
    for line in payload.splitlines():
        low = line.strip().lower()
        if low in {"```", "```json", "```text", "```yaml"}:
            removed = True
            continue
        if any(fragment in low for fragment in blocked_fragments):
            removed = True
            continue
        if any(re.search(pattern, low) for pattern in noisy_line_patterns):
            removed = True
            continue
        filtered_lines.append(line)

    payload = "\n".join(filtered_lines)
    payload = re.sub(r"\n{3,}", "\n\n", payload).strip()
    if not payload:
        return "", original != ""
    return payload, (removed or payload != original)


def _looks_like_internal_dump(text: str) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è ¬´–ø—Ä–æ—Ç–µ–∫—à–µ–≥–æ¬ª –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤—ã–≤–æ–¥–∞:
    schema-–¥–∞–º–ø—ã, —Å–∏—Å—Ç–µ–º–Ω—ã–µ markdown-–±–ª–æ–∫–∏, —Ç–µ—Ö. —Ç–µ–≥–∏ –∏ –æ–¥–Ω–æ—Ç–∏–ø–Ω—ã–µ JSON-—Å—Ç—Ä–æ–∫–∏.
    """
    payload = str(text or "").strip()
    if not payload:
        return False

    low = payload.lower()
    suspicious_markers = (
        "begin_of_box",
        "end_of_box",
        "sessions_send",
        "sessionkey",
        "default channel",
        "agents.md",
        "## agent list",
        "no_reply",
        "heartbeat_ok",
    )
    marker_hits = sum(1 for marker in suspicious_markers if marker in low)

    jsonish_line_count = 0
    for line in payload.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if re.match(r'^\s*"?[A-Za-z_][A-Za-z0-9_ ]*"?\s*:\s*', stripped):
            jsonish_line_count += 1

    if marker_hits >= 2:
        return True
    if marker_hits >= 1 and jsonish_line_count >= 10:
        return True
    if jsonish_line_count >= 24:
        return True
    return False


def _clamp_auto_reply_text(text: str, *, is_private: bool) -> tuple[str, bool]:
    """
    –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –¥–ª–∏–Ω—É –æ—Ç–≤–µ—Ç–∞ –¥–ª—è –∫–∞–Ω–∞–ª–æ–≤ –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç–∞, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å
    –æ–≥—Ä–æ–º–Ω—ã—Ö ¬´–ø—Ä–æ—Å—Ç—ã–Ω–µ–π¬ª –∏ –∑–∞—Ü–∏–∫–ª–µ–Ω–Ω–æ–≥–æ –≤—ã–≤–æ–¥–∞.
    """
    payload = str(text or "").strip()
    if not payload:
        return "", False

    max_chars = (
        AUTO_REPLY_MAX_RESPONSE_CHARS_PRIVATE
        if is_private
        else AUTO_REPLY_MAX_RESPONSE_CHARS
    )
    if len(payload) <= max_chars:
        return payload, False
    trimmed = payload[: max(200, max_chars)].rstrip()
    return f"{trimmed}\n\n‚Ä¶(–æ—Ç–≤–µ—Ç —Å–æ–∫—Ä–∞—â–µ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)", True


def _drop_english_scaffold_when_russian_expected(
    text: str,
    prefer_russian: bool,
    min_paragraph_len: int = 180,
) -> tuple[str, bool]:
    """
    –£–¥–∞–ª—è–µ—Ç –¥–ª–∏–Ω–Ω—ã–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ scaffold-–±–ª–æ–∫–∏, –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –Ω–∞ —Ä—É—Å—Å–∫–æ–º.
    –°—Ü–µ–Ω–∞—Ä–∏–π: –º–æ–¥–µ–ª—å –≤—ã–¥–∞–ª–∞ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π —á–µ—Ä–Ω–æ–≤–∏–∫ + —Ä—É—Å—Å–∫–∏–π –æ—Ç–≤–µ—Ç –≤ –æ–¥–Ω–æ–º —Å–æ–æ–±—â–µ–Ω–∏–∏.
    """
    payload = str(text or "").strip()
    if not payload or not prefer_russian:
        return payload, False

    paragraphs = [p.strip() for p in re.split(r"\n{2,}", payload) if p.strip()]
    if not paragraphs:
        return payload, False

    def _letters_stats(value: str) -> tuple[int, int]:
        latin = len(re.findall(r"[A-Za-z]", value))
        cyr = len(re.findall(r"[–ê-–Ø–∞-—è–Å—ë]", value))
        return latin, cyr

    has_substantial_russian = any(
        len(p) >= 80 and _letters_stats(p)[1] >= 20 for p in paragraphs
    )
    if not has_substantial_russian:
        return payload, False

    removed = False
    kept: list[str] = []
    for paragraph in paragraphs:
        latin, cyr = _letters_stats(paragraph)
        is_long = len(paragraph) >= max(80, int(min_paragraph_len))
        latin_ratio = float(latin) / float(max(1, latin + cyr))
        if is_long and latin >= 80 and cyr <= 18 and latin_ratio >= 0.78:
            removed = True
            continue
        kept.append(paragraph)

    if not removed or not kept:
        return payload, False
    return "\n\n".join(kept).strip(), True


def _is_service_busy_artifact_text(text: str) -> bool:
    """
    –û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, —á—Ç–æ —Å—Ç—Ä–æ–∫–∞ —è–≤–ª—è–µ—Ç—Å—è —Å–ª—É–∂–µ–±–Ω—ã–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–º –æ—á–µ—Ä–µ–¥–∏/–æ–∂–∏–¥–∞–Ω–∏—è,
    –∫–æ—Ç–æ—Ä—ã–π –Ω–µ –¥–æ–ª–∂–µ–Ω –ø–æ–ø–∞–¥–∞—Ç—å –æ–±—Ä–∞—Ç–Ω–æ –≤ –º–æ–¥–µ–ª—å–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç.
    """
    payload = str(text or "").strip().lower()
    if not payload:
        return False
    markers = (
        "–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –ø—Ä–µ–¥—ã–¥—É—â–∏–π –∑–∞–ø—Ä–æ—Å",
        "–æ—Ç–ø—Ä–∞–≤—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥",
        "–ø–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –∏ –ø–æ–≤—Ç–æ—Ä–∏",
        "–¥–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏",
    )
    return any(marker in payload for marker in markers)


def _drop_service_busy_context_items(context: list) -> tuple[list, int]:
    """
    –£–¥–∞–ª—è–µ—Ç –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —ç–ª–µ–º–µ–Ω—Ç—ã —Å —Ç–µ—Ö—Ñ—Ä–∞–∑–∞–º–∏ –æ—á–µ—Ä–µ–¥–∏ (–ª—é–±–æ–π —Ä–æ–ª–∏),
    —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å –Ω–µ –∫–æ–ø–∏—Ä–æ–≤–∞–ª–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.
    """
    cleaned: list = []
    dropped = 0
    for item in context or []:
        text = str((item or {}).get("text", "") or "")
        if _is_service_busy_artifact_text(text):
            dropped += 1
            continue
        cleaned.append(item)
    return cleaned, dropped


def _build_stream_preview(text: str, max_chars: int = 3600) -> str:
    """
    –ì–æ—Ç–æ–≤–∏—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è live-–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –≤ Telegram.
    –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ö–≤–æ—Å—Ç –¥–ª–∏–Ω–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞, —á—Ç–æ–±—ã –Ω–µ —É–ø–∏—Ä–∞—Ç—å—Å—è –≤ –ª–∏–º–∏—Ç edit_text.
    """
    if not text:
        return "..."
    payload = str(text)
    if len(payload) <= max_chars:
        return payload
    tail = payload[-max_chars:]
    return f"‚Ä¶\n{tail}"


def _split_text_chunks_for_telegram(text: str, max_len: int = 3900) -> list[str]:
    """
    –î–µ–ª–∏—Ç –¥–ª–∏–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –∫—É—Å–∫–∏ –¥–ª—è Telegram.
    –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ—Ç –≥—Ä–∞–Ω–∏—Ü—ã –∞–±–∑–∞—Ü–µ–≤/—Å—Ç—Ä–æ–∫, —á—Ç–æ–±—ã –Ω–µ —Ä—É–±–∏—Ç—å –º—ã—Å–ª—å –ø–æ—Å–µ—Ä–µ–¥–∏–Ω–µ.
    """
    payload = str(text or "")
    limit = int(max(500, max_len))
    if len(payload) <= limit:
        return [payload]

    chunks: list[str] = []
    rest = payload
    while len(rest) > limit:
        window = rest[:limit]
        cut = window.rfind("\n\n")
        if cut < int(limit * 0.45):
            cut = window.rfind("\n")
        if cut < int(limit * 0.35):
            cut = window.rfind(". ")
        if cut < int(limit * 0.25):
            cut = limit
        part = rest[:cut].rstrip()
        if not part:
            part = rest[:limit]
            cut = len(part)
        chunks.append(part)
        rest = rest[cut:].lstrip()
    if rest:
        chunks.append(rest)
    return chunks


def _should_emit_stream_edit(previous_preview: str, next_preview: str, min_delta_chars: int = 60) -> bool:
    """
    –†–µ—à–∞–µ—Ç, —Å—Ç–æ–∏—Ç –ª–∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –æ—á–µ—Ä–µ–¥–Ω–æ–π edit_text –≤–æ –≤—Ä–µ–º—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞.
    –£–º–µ–Ω—å—à–∞–µ—Ç ¬´—à—É–º¬ª –∏ —Ä–∏—Å–∫ FloodWait –Ω–∞ –¥–ª–∏–Ω–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏—è—Ö.
    """
    prev = str(previous_preview or "")
    nxt = str(next_preview or "")
    if not nxt:
        return False
    if not prev:
        return True
    if prev == nxt:
        return False
    return abs(len(nxt) - len(prev)) >= int(max(1, min_delta_chars))


def _looks_incomplete_response(text: str) -> bool:
    """
    –≠–≤—Ä–∏—Å—Ç–∏–∫–∞ ¬´–æ–±—Ä–µ–∑–∞–Ω–Ω–æ–≥–æ¬ª –æ—Ç–≤–µ—Ç–∞: –º–æ–¥–µ–ª—å –æ–±–µ—â–∞–ª–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—É/–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ,
    –Ω–æ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å –Ω–∞ –≤–≤–æ–¥–Ω–æ–π —Ñ—Ä–∞–∑–µ –∏–ª–∏ –Ω–∞ —è–≤–Ω–æ–º –Ω–µ–∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ–º –∫–æ–Ω—Ü–µ.
    """
    payload = str(text or "").strip()
    if not payload:
        return False

    low = payload.lower()
    if len(payload) < 60:
        return False

    numbered_items = re.search(r"(?m)^\s*\d+[\.\)]\s+", payload) is not None
    promised_plan = any(
        marker in low
        for marker in (
            "–ø–æ—à–∞–≥–æ–≤—ã–π –ø–ª–∞–Ω",
            "–ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π",
            "–≤–æ—Ç –ø–ª–∞–Ω",
            "step-by-step",
            "–≤–æ—Ç —à–∞–≥–∏",
        )
    )
    unfinished_tail = payload.endswith((":", ",", "‚Äî", "-", "‚Ä¶", "..."))
    no_final_punctuation = payload[-1] not in ".!?)¬ª\"'"

    if promised_plan and not numbered_items:
        return True
    if unfinished_tail:
        return True
    if no_final_punctuation and len(payload) >= 220:
        return True
    return False


def _filter_context_for_group_author(
    context: list,
    current_author_id: int,
    is_private: bool,
    is_owner_sender: bool,
    enabled: bool = True,
) -> tuple[list, bool]:
    """
    –î–ª—è –≥—Ä—É–ø–ø–æ–≤—ã—Ö —á–∞—Ç–æ–≤ —Å —É—á–∞—Å—Ç–Ω–∏–∫–∞–º–∏ (–Ω–µ owner) –æ—Å—Ç–∞–≤–ª—è–µ–º –≤ user-–∫–æ–Ω—Ç–µ–∫—Å—Ç–µ
    —Ç–æ–ª—å–∫–æ —Å–æ–æ–±—â–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∞–≤—Ç–æ—Ä–∞, —á—Ç–æ–±—ã —Å–Ω–∏–∑–∏—Ç—å –ø–µ—Ä–µ–Ω–æ—Å ¬´—á—É–∂–æ–π –ª–∏—á–Ω–æ—Å—Ç–∏¬ª.

    Assistant/system/tool –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
    """
    if not enabled or is_private or is_owner_sender or not current_author_id:
        return context, False

    marker = f"author_id={int(current_author_id)}"
    filtered: list = []
    trimmed = False
    for item in context or []:
        role = str((item or {}).get("role", "user")).strip().lower()
        if role != "user":
            filtered.append(item)
            continue
        # –ü—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —è–≤–Ω—É—é –º–µ—Ç–∫—É –∞–≤—Ç–æ—Ä–∞ –≤ payload (–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ, —á–µ–º –ø–∞—Ä—Å–∏—Ç—å —Ç–µ–∫—Å—Ç).
        try:
            item_author_id = int((item or {}).get("author_id") or 0)
        except Exception:
            item_author_id = 0
        if item_author_id:
            if item_author_id == int(current_author_id):
                filtered.append(item)
            else:
                trimmed = True
            continue
        text = str((item or {}).get("text", "") or "")
        if marker in text:
            filtered.append(item)
        else:
            trimmed = True
    return filtered, trimmed


async def _safe_stream_edit_text(reply_msg: Message, text: str) -> None:
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ edit_text –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞:
    1) –ø—Ä–æ–±—É–µ–º markdown-—Å–∞–Ω–∏t–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç,
    2) –ø—Ä–∏ –ø—Ä–æ–≤–∞–ª–µ –ø—Ä–æ–±—É–µ–º plain text –±–µ–∑ parse_mode.
    """
    safe_text = sanitize_markdown_for_telegram(text)
    try:
        await reply_msg.edit_text(safe_text)
        return
    except Exception as markdown_error:
        plain = _to_plain_stream_text(safe_text)
        try:
            await reply_msg.edit_text(plain, parse_mode=None)
            return
        except Exception as plain_error:
            logger.debug(
                "Stream edit_text skipped after markdown/plain fallback failures",
                markdown_error=str(markdown_error),
                plain_error=str(plain_error),
            )


def _message_content_hint(msg: Message) -> str:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –¥–µ—Å–∫—Ä–∏–ø—Ç–æ—Ä –ª—é–±–æ–≥–æ —Ç–∏–ø–∞ —Å–æ–æ–±—â–µ–Ω–∏—è."""
    text = _sanitize_model_output(msg.text or msg.caption or "")
    if text:
        return text
    if msg.voice:
        return "[VOICE] –ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ"
    if msg.audio:
        title = ""
        if msg.audio and getattr(msg.audio, "title", None):
            title = f" ({msg.audio.title})"
        return f"[AUDIO] –ê—É–¥–∏–æ{title}"
    if msg.sticker:
        emoji = getattr(msg.sticker, "emoji", "") or ""
        return f"[STICKER] {emoji}".strip()
    if msg.animation:
        return "[GIF] –ê–Ω–∏–º–∞—Ü–∏—è"
    if msg.video:
        return "[VIDEO] –í–∏–¥–µ–æ"
    if msg.photo:
        return "[PHOTO] –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"
    if msg.document:
        name = getattr(msg.document, "file_name", "") or ""
        return f"[DOCUMENT] {name}".strip()
    if msg.poll:
        question = getattr(msg.poll, "question", "") or ""
        return f"[POLL] {question}".strip()
    media_type = getattr(getattr(msg, "media", None), "value", "")
    if media_type:
        return f"[{str(media_type).upper()}] –ú–µ–¥–∏–∞-—Å–æ–æ–±—â–µ–Ω–∏–µ"
    return ""


async def set_message_reaction(client, chat_id: int, message_id: int, emoji: str):
    """–°—Ç–∞–≤–∏—Ç —Ä–µ–∞–∫—Ü–∏—é (emoji) –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ."""
    try:
        # –í Pyrogram v2+ send_reaction –ø—Ä–∏–Ω–∏–º–∞–µ—Ç emoji –∫–∞–∫ —Å—Ç—Ä–æ–∫—É
        await client.send_reaction(chat_id, message_id, emoji)
    except Exception as e:
        logger.debug(f"Reaction failed: {e}")


async def _await_if_needed(value):
    """–û–∂–∏–¥–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–Ω–æ awaitable."""
    if inspect.isawaitable(value):
        return await value
    return value


def _extract_text_from_media_payload(payload: Any) -> str:
    """
    –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –æ—Ç–≤–µ—Ç –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω—ã—Ö –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–π (perceptor/openclaw) –≤ —Å—Ç—Ä–æ–∫—É.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç string/dict/list —Ñ–æ—Ä–º–∞—Ç—ã.
    """
    if payload is None:
        return ""
    if isinstance(payload, str):
        return payload.strip()
    if isinstance(payload, dict):
        for key in ("text", "description", "transcript", "result", "answer"):
            value = payload.get(key)
            if isinstance(value, str) and value.strip():
                return value.strip()
        content = payload.get("content")
        if isinstance(content, list):
            for item in content:
                if isinstance(item, dict):
                    text = item.get("text")
                    if isinstance(text, str) and text.strip():
                        return text.strip()
                elif isinstance(item, str) and item.strip():
                    return item.strip()
    if isinstance(payload, list):
        for item in payload:
            extracted = _extract_text_from_media_payload(item)
            if extracted:
                return extracted
    return str(payload).strip()


async def _process_auto_reply(client, message: Message, deps: dict):
    """
    –£–º–Ω—ã–π –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫ v3 (Omni-channel + Reactions + Multimodal).
    """
    security = deps["security"]
    rate_limiter = deps["rate_limiter"]
    memory = deps["memory"]
    router = deps["router"]
    config_manager = deps.get("config_manager")
    perceptor = deps.get("perceptor")
    openclaw = deps.get("openclaw_client")
    summarizer = deps.get("summarizer")
    ai_runtime: AIRuntimeControl | None = deps.get("ai_runtime")
    reaction_engine: ReactionLearningEngine | None = deps.get("reaction_engine")
    
    sender = message.from_user.username if message.from_user else "Unknown"
    is_owner_sender = bool(is_owner(message))
    logger.debug(
        "auto_reply: —Å—Ç–∞—Ä—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏",
        chat_id=message.chat.id,
        message_id=message.id,
        sender=sender,
        is_owner_sender=is_owner_sender,
        chat_type=str(getattr(message.chat.type, "name", message.chat.type)),
    )

    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —á–µ—Ä–µ–∑ SecurityManager
    role = security.get_user_role(sender, message.from_user.id if message.from_user else 0)
    logger.debug(
        "auto_reply: —Ä–∞—Å—Å—á–∏—Ç–∞–Ω–∞ —Ä–æ–ª—å –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è",
        chat_id=message.chat.id,
        message_id=message.id,
        sender=sender,
        role=role,
    )
    
    if role == "blocked":
            logger.debug("auto_reply: –ø—Ä–æ–ø—É—Å–∫ blocked role", chat_id=message.chat.id, message_id=message.id, sender=sender)
            return

    if role == "stealth_restricted":
        logger.debug("auto_reply: –ø—Ä–æ–ø—É—Å–∫ stealth mode", chat_id=message.chat.id, message_id=message.id, sender=sender)
        return

    # 2. –õ–æ–≥–∏–∫–∞ —Å—Ä–∞–±–∞—Ç—ã–≤–∞–Ω–∏—è (Smart Reply v2.0)
    is_private = message.chat.type == enums.ChatType.PRIVATE
    is_reply_to_me = (
        message.reply_to_message and 
        message.reply_to_message.from_user and 
        message.reply_to_message.from_user.is_self
    )
    
    me = await client.get_me()
    is_mentioned = False
    text_content = _message_content_hint(message)
    
    if text_content:
        text_lower = text_content.lower()
        is_mentioned = (
            "–∫—Ä–∞–±" in text_lower or 
            (me.username and f"@{me.username.lower()}" in text_lower)
        )

    allow_group_replies = True
    if config_manager:
        allow_group_replies = config_manager.get("group_chat.allow_replies", True)

    should_reply = False
    if is_private:
        should_reply = True
    elif is_mentioned:
        should_reply = True
    elif is_reply_to_me and allow_group_replies:
        should_reply = True

    if not should_reply:
        logger.debug(
            "auto_reply: –ø—Ä–æ–ø—É—Å–∫, –Ω–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —É—Å–ª–æ–≤–∏—è –æ—Ç–≤–µ—Ç–∞",
            chat_id=message.chat.id,
            message_id=message.id,
            is_private=is_private,
            is_mentioned=is_mentioned,
            is_reply_to_me=bool(is_reply_to_me),
        )
        memory.save_message(
            message.chat.id,
            _build_user_memory_payload(
                message=message,
                sender=sender,
                text=text_content,
                is_owner_sender=is_owner_sender,
            ),
        )
        return
    if is_private:
        logger.info(
            "auto_reply: –ø—Ä–∏–≤–∞—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø—Ä–∏–Ω—è—Ç–æ –≤ –æ–±—Ä–∞–±–æ—Ç–∫—É",
            chat_id=message.chat.id,
            message_id=message.id,
            sender=sender,
            is_owner_sender=is_owner_sender,
        )

    # –ê–Ω—Ç–∏—Å–ø–∞–º
    has_rich_media = bool(
        message.photo or message.voice or message.audio or 
        message.sticker or message.animation or message.video or message.document
    )
    if not is_private and len(text_content) < 2 and not is_reply_to_me and not has_rich_media:
        logger.debug("auto_reply: –ø—Ä–æ–ø—É—Å–∫ anti-spam —Ñ–∏–ª—å—Ç—Ä", chat_id=message.chat.id, message_id=message.id)
        return

    # Rate Limiting
    user_id = message.from_user.id if message.from_user else 0
    if not rate_limiter.is_allowed(user_id):
        logger.warning("auto_reply: –ø—Ä–æ–ø—É—Å–∫ rate limit", chat_id=message.chat.id, message_id=message.id, user_id=user_id)
        if is_private:
            try:
                await message.reply_text("‚è≥ –°–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤ –ø–æ–¥—Ä—è–¥. –ü–æ–¥–æ–∂–¥–∏ –Ω–µ–º–Ω–æ–≥–æ –∏ –ø–æ–≤—Ç–æ—Ä–∏.")
            except Exception:
                pass
        return

    # 2. –û–±—Ä–∞–±–æ—Ç–∫–∞ –º—É–ª—å—Ç–∏–º–µ–¥–∏–∞ (Vision / Voice / Video / Docs / Stickers)
    visual_context = ""
    transcribed_text = ""
    vision_route_fact_line = ""
    vision_route_meta: dict = {}
    is_voice_response_needed = _is_voice_reply_requested(text_content)
    temp_files = []

    try:
        # --- PHOTO (Vision) ---
        if message.photo:
            await client.send_chat_action(message.chat.id, action=enums.ChatAction.UPLOAD_PHOTO)
            photo_path = await message.download()
            temp_files.append(photo_path)
            if perceptor:
                vision_raw = await perceptor.analyze_image(
                    photo_path,
                    router,
                    prompt="–û–ø–∏—à–∏ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–¥—Ä–æ–±–Ω–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ.",
                )
                vision_result = _sanitize_model_output(
                    _extract_text_from_media_payload(vision_raw),
                    router,
                )
                if hasattr(perceptor, "get_last_vision_meta"):
                    try:
                        vision_route_meta = perceptor.get_last_vision_meta() or {}
                        vision_route_fact_line = _build_vision_route_fact_line(vision_route_meta)
                    except Exception:
                        vision_route_meta = {}
                        vision_route_fact_line = ""
            elif openclaw and hasattr(openclaw, "analyze_image"):
                vision_raw = await _await_if_needed(openclaw.analyze_image(photo_path))
                vision_result = _sanitize_model_output(
                    _extract_text_from_media_payload(vision_raw),
                    router,
                )
            else:
                await message.reply_text("‚ùå Vision module –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                return
            if vision_result and not vision_result.startswith("–û—à–∏–±–∫–∞"):
                visual_context = f"[VISION ANALYSIS]: User sent a photo. Description: {vision_result}"
            else:
                visual_context = "[VISION ERROR]: Failed to analyze photo."

        # --- VOICE / AUDIO (STT) ---
        elif message.voice or message.audio:
            status_msg = None
            await client.send_chat_action(message.chat.id, action=enums.ChatAction.RECORD_AUDIO)
            try:
                status_msg = await message.reply_text("üëÇ –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å...")
            except Exception:
                status_msg = None
            audio_path = await message.download()
            temp_files.append(audio_path)
            if perceptor:
                transcription_raw = await perceptor.transcribe(audio_path, router)
            elif openclaw and hasattr(openclaw, "transcribe_audio"):
                transcription_raw = await _await_if_needed(openclaw.transcribe_audio(audio_path))
            else:
                await message.reply_text("‚ùå Voice module –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                return
            transcribed_text = _sanitize_model_output(
                _extract_text_from_media_payload(transcription_raw),
                router,
            )
            if transcribed_text and not transcribed_text.startswith("–û—à–∏–±–∫–∞"):
                if message.voice:
                    is_voice_response_needed = True
                if status_msg:
                    try:
                        await status_msg.delete()
                    except Exception:
                        pass
            else:
                human_error = transcribed_text or "–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ."
                if status_msg:
                    try:
                        await status_msg.edit_text(f"‚ö†Ô∏è {human_error[:450]}")
                    except Exception:
                        pass
                else:
                    await message.reply_text(f"‚ö†Ô∏è {human_error[:450]}")
                return

        # --- VIDEO / GIF (Deep Analysis) ---
        elif message.video or message.animation:
            if not perceptor:
                await message.reply_text("‚ùå Vision module –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                return
            await client.send_chat_action(message.chat.id, action=enums.ChatAction.UPLOAD_VIDEO)
            notif = await message.reply_text("üé¨ **–°–º–æ—Ç—Ä—é...**")
            media_path = await message.download()
            temp_files.append(media_path)
            # –î–ª—è GIF/Video –∏—Å–ø–æ–ª—å–∑—É–µ–º Gemini Video Analysis
            video_result = _sanitize_model_output(
                await perceptor.analyze_video(
                    media_path,
                    router,
                    prompt="–û–ø–∏—à–∏ –æ—á–µ–Ω—å –∫—Ä–∞—Ç–∫–æ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è), —á—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –Ω–∞ –≤–∏–¥–µ–æ/–≥–∏—Ñ–∫–µ. –ö–∞–∫–æ–π –æ—Å–Ω–æ–≤–Ω–æ–π –ø–æ—Å—ã–ª –∏–ª–∏ —ç–º–æ—Ü–∏—è?",
                ),
                router,
            )
            if video_result and not video_result.startswith("–û—à–∏–±–∫–∞"):
                visual_context = f"[MEDIA ANALYSIS]: {video_result}"
                await notif.delete()
            else:
                await notif.edit_text(f"‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {video_result}")
                visual_context = "[MEDIA ERROR]: Failed to analyze video/gif."

        # --- DOCUMENT ---
        elif message.document:
            if not perceptor:
                await message.reply_text("‚ùå Document module –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω.")
                return
            await client.send_chat_action(message.chat.id, action=enums.ChatAction.UPLOAD_DOCUMENT)
            notif = await message.reply_text("üìÑ **–ß–∏—Ç–∞—é...**")
            doc_path = await message.download()
            temp_files.append(doc_path)
            doc_result = _sanitize_model_output(
                await perceptor.analyze_document(
                    doc_path,
                    router,
                    prompt="–°–¥–µ–ª–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ–±–∑–æ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º.",
                ),
                router,
            )
            if doc_result and not doc_result.startswith("–û—à–∏–±–∫–∞"):
                visual_context = f"[DOCUMENT ANALYSIS]: {doc_result}"
                await notif.delete()
            else:
                await notif.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {doc_result}")
                visual_context = "[DOCUMENT ERROR]: Failed to analyze document."

        # --- STICKER ---
        elif message.sticker:
            emoji = message.sticker.emoji or "üé®"
            visual_context = f"[USER SENT A STICKER: {emoji}]"
            # –î–ª—è —Å—Ç–∏–∫–µ—Ä–æ–≤ –º–æ–∂–Ω–æ —Å—Ä–∞–∑—É –ø–æ—Å—Ç–∞–≤–∏—Ç—å —Ä–µ–∞–∫—Ü–∏—é "–≥–ª–∞–∑–∞" –∏–ª–∏ "—Å–µ—Ä–¥—Ü–µ".
            await set_message_reaction(client, message.chat.id, message.id, "üëÄ")

    except Exception as e:
        logger.error(f"Media processing error: {e}")
    finally:
        for p in temp_files:
            try:
                if os.path.exists(p): os.remove(p)
            except: pass

    # Context gathering
    reply_context = _build_reply_context(message)
    forward_context = _build_forward_context(
        message,
        enabled=bool(ai_runtime and ai_runtime.forward_context_enabled),
    )
    is_forwarded_input = _is_forwarded_message(message)

    # Final prompt
    final_prompt = f"{transcribed_text} (Voice Input)" if transcribed_text else text_content
    prefer_russian_response = _should_force_russian_reply(
        user_text=text_content,
        is_private=is_private,
        is_owner_sender=is_owner_sender,
        is_voice_response_needed=is_voice_response_needed,
    )
    author_context = _build_author_context(message, is_owner_sender=is_owner_sender)
    if author_context:
        final_prompt = f"{author_context}\n\n{final_prompt}"
    if visual_context:
        final_prompt = f"{visual_context}\n\nUser Says: {final_prompt}"
    if vision_route_fact_line:
        final_prompt = (
            f"[VISION ROUTE FACT]: {vision_route_fact_line}\n"
            "–≠—Ç–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π —Ñ–∞–∫—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–ø—Ä–æ—Å–∞. –ù–µ –∏—Å–∫–∞–∂–∞–π –µ–≥–æ –∏ –Ω–µ —É—Ç–≤–µ—Ä–∂–¥–∞–π –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω–æ–µ.\n\n"
            f"{final_prompt}"
        )
    if reply_context:
        final_prompt = f"{reply_context}\n\n{final_prompt}"
    if forward_context:
        forward_guard = (
            "–ù–∏–∂–µ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –ø–æ –Ω–µ–º—É.\n"
            "–ù–µ –ø—Ä–æ–¥–æ–ª–∂–∞–π —Å—Ç–∞—Ä—É—é —Ç–µ–º—É –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —ç—Ç–æ–≥–æ —è–≤–Ω–æ –Ω–µ –ø—Ä–æ—Å–∏–ª.\n"
            "–ï—Å–ª–∏ –≤ –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω–æ–º —Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç —è–≤–Ω–æ–≥–æ –≤–æ–ø—Ä–æ—Å–∞/–∑–∞–¥–∞—á–∏ ‚Äî –∫–æ—Ä–æ—Ç–∫–æ —É—Ç–æ—á–Ω–∏, —á—Ç–æ –∏–º–µ–Ω–Ω–æ —Å–¥–µ–ª–∞—Ç—å:"
            " —Å—É–º–º–∞—Ä–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å, –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –Ω–µ–≥–æ –∏–ª–∏ –∏–∑–≤–ª–µ—á—å —Ñ–∞–∫—Ç—ã."
        )
        final_prompt = f"{forward_context}\n\n{forward_guard}\n\n{final_prompt}"
    if reaction_engine and ai_runtime and ai_runtime.chat_mood_enabled:
        mood_line = reaction_engine.build_mood_context_line(message.chat.id)
        if mood_line:
            final_prompt = f"{mood_line}\n\n{final_prompt}"
    if prefer_russian_response:
        final_prompt = (
            "–û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –µ—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —è–≤–Ω–æ –Ω–µ –ø–æ–ø—Ä–æ—Å–∏–ª –¥—Ä—É–≥–æ–π —è–∑—ã–∫.\n"
            "–ù–µ –≤—Å—Ç–∞–≤–ª—è–π –¥–ª–∏–Ω–Ω—ã–µ –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã–µ –±–ª–æ–∫–∏ –∏ –Ω–µ —Å–º–µ—à–∏–≤–∞–π —è–∑—ã–∫–∏ –≤ –æ–¥–Ω–æ–º –æ—Ç–≤–µ—Ç–µ.\n"
            "–ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–ø—É—Å–∫–∞ –∫–æ–º–∞–Ω–¥/–æ–±–Ω–æ–≤–ª–µ–Ω–∏–π; –µ—Å–ª–∏ —á–µ–≥–æ-—Ç–æ –Ω–µ –≤—ã–ø–æ–ª–Ω—è–ª ‚Äî —Å–∫–∞–∂–∏ —ç—Ç–æ –ø—Ä—è–º–æ.\n\n"
            f"{final_prompt}"
        )
    if is_voice_response_needed:
        final_prompt = (
            "–û—Ç–≤–µ—Ç—å —Å—Ç—Ä–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –¥—Ä—É–∂–µ–ª—é–±–Ω–æ –∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ.\n"
            "–ë–µ–∑ —Å–ª—É–∂–µ–±–Ω—ã—Ö —Ñ—Ä–∞–∑, –±–µ–∑ —Å—Ç–∞—Ç—É—Å–æ–≤, –±–µ–∑ –º–µ—Ç–∞-–∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤ –≤ —Å–∫–æ–±–∫–∞—Ö.\n"
            "–ï—Å–ª–∏ —ç—Ç–æ —Å–∫–∞–∑–∫–∞/–∏—Å—Ç–æ—Ä–∏—è ‚Äî –¥–∞–π —Ü–µ–ª—å–Ω—ã–π –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–Ω—ã–π —Ç–µ–∫—Å—Ç.\n\n"
            f"{final_prompt}"
        )

    # Sync & Save
    try:
        await asyncio.wait_for(
            memory.sync_telegram_history(client, message.chat.id, limit=30),
            timeout=max(2.0, float(AUTO_REPLY_HISTORY_SYNC_TIMEOUT_SECONDS)),
        )
    except asyncio.TimeoutError:
        logger.warning(
            "auto_reply: sync_telegram_history timeout, –ø—Ä–æ–¥–æ–ª–∂–∞—é –±–µ–∑ –ø–æ–ª–Ω–æ–π —Å–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∞—Ü–∏–∏",
            chat_id=message.chat.id,
            message_id=message.id,
            timeout_seconds=float(AUTO_REPLY_HISTORY_SYNC_TIMEOUT_SECONDS),
        )
    except Exception as sync_exc:
        logger.warning(
            "auto_reply: sync_telegram_history failed, –ø—Ä–æ–¥–æ–ª–∂–∞—é —Å –ª–æ–∫–∞–ª—å–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º",
            chat_id=message.chat.id,
            message_id=message.id,
            error=str(sync_exc),
        )
    chat_type_value = str(getattr(message.chat.type, "name", message.chat.type)).lower()
    memory.save_message(
        message.chat.id,
        _build_user_memory_payload(
            message=message,
            sender=sender,
            text=final_prompt,
            is_owner_sender=is_owner_sender,
        ),
    )
    
    if summarizer and AUTO_SUMMARY_ENABLED:
        asyncio.create_task(summarizer.auto_summarize(message.chat.id))

    # Routing
    context = memory.get_token_aware_context(message.chat.id, max_tokens=AUTO_REPLY_CONTEXT_TOKENS)
    if is_forwarded_input:
        # –î–ª—è —Ñ–æ—Ä–≤–∞—Ä–¥–æ–≤ –Ω–µ —Ç–∞—â–∏–º –¥–ª–∏–Ω–Ω—ã–π —Ö–≤–æ—Å—Ç —Å—Ç–∞—Ä–æ–≥–æ –¥–∏–∞–ª–æ–≥–∞, —á—Ç–æ–±—ã –Ω–µ ¬´–∑–∞–ª–∏–ø–∞—Ç—å¬ª –≤ –ø—Ä–æ—à–ª—É—é —Ç–µ–º—É.
        context = []
    user_context_before = sum(
        1 for item in (context or []) if str((item or {}).get("role", "user")).strip().lower() == "user"
    )
    context, group_author_context_trimmed = _filter_context_for_group_author(
        context=context,
        current_author_id=user_id,
        is_private=is_private,
        is_owner_sender=is_owner_sender,
        enabled=bool(ai_runtime and ai_runtime.group_author_isolation_enabled),
    )
    context, dropped_service_context_items = _drop_service_busy_context_items(context)
    user_context_after = sum(
        1 for item in (context or []) if str((item or {}).get("role", "user")).strip().lower() == "user"
    )
    dropped_user_context_items = max(0, int(user_context_before - user_context_after))
    if ai_runtime:
        ai_runtime.set_context_snapshot(
            message.chat.id,
            {
                "chat_id": int(message.chat.id),
                "message_id": int(message.id),
                "context_messages": len(context or []),
                "prompt_length_chars": len(final_prompt or ""),
                "has_forward_context": bool(forward_context),
                "is_forwarded_input": bool(is_forwarded_input),
                "has_reply_context": bool(reply_context),
                "group_author_isolation_enabled": bool(ai_runtime.group_author_isolation_enabled),
                "continue_on_incomplete_enabled": bool(ai_runtime.continue_on_incomplete_enabled),
                "group_author_context_trimmed": bool(group_author_context_trimmed),
                "group_author_context_user_messages_before": int(user_context_before),
                "group_author_context_user_messages_after": int(user_context_after),
                "group_author_context_dropped_user_messages": int(dropped_user_context_items),
                "service_artifact_context_items_dropped": int(dropped_service_context_items),
                "continue_on_incomplete_triggered": False,
                "continue_on_incomplete_applied": False,
                "updated_at": int(time.time()),
            },
        )
    
    # Typing indicator
    await client.send_chat_action(message.chat.id, action=enums.ChatAction.TYPING)
    reply_msg = await message.reply_text("ü§î **–î—É–º–∞—é...**")
    logger.debug("auto_reply: –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω thinking placeholder", chat_id=message.chat.id, message_id=message.id)
    
    full_response = ""
    last_update = 0
    last_preview_sent = ""

    async def _iter_router_parts():
        """
        –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Å—Ç—Ä–∏–º-–∞–¥–∞–ø—Ç–µ—Ä:
        1) route_stream (—Ç–µ–∫—É—â–∏–π API),
        2) route_query_stream (legacy API),
        3) route_query (single-shot fallback).
        """
        route_kwargs = {
            "prompt": final_prompt,
            "task_type": "chat",
            "context": context,
            "chat_type": message.chat.type.name.lower(),
            "is_owner": is_owner_sender,
        }

        route_stream = getattr(router, "route_stream", None)
        if callable(route_stream):
            try:
                stream_candidate = route_stream(**route_kwargs)
                if hasattr(stream_candidate, "__aiter__"):
                    streamed_any = False
                    async for part in stream_candidate:
                        streamed_any = True
                        yield part
                    if streamed_any:
                        return
            except Exception as stream_exc:
                logger.debug("auto_reply: route_stream fallback", error=str(stream_exc))

        route_query_stream = getattr(router, "route_query_stream", None)
        if callable(route_query_stream):
            try:
                stream_candidate = route_query_stream(**route_kwargs)
                if hasattr(stream_candidate, "__aiter__"):
                    streamed_any = False
                    async for part in stream_candidate:
                        streamed_any = True
                        yield part
                    if streamed_any:
                        return
            except Exception as stream_exc:
                logger.debug("auto_reply: route_query_stream fallback", error=str(stream_exc))

        route_query = getattr(router, "route_query", None)
        if callable(route_query):
            try:
                single = await _await_if_needed(route_query(**route_kwargs))
                single_text = str(single or "").strip()
                if single_text:
                    yield single_text
            except Exception as query_exc:
                logger.debug("auto_reply: route_query fallback failed", error=str(query_exc))
    
    async def run_streaming():
        nonlocal full_response, last_update, last_preview_sent
        try:
            async for part in _iter_router_parts():
                full_response += part
                curr_t = time.time()
                # –ü–ª–∞–≤–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–≤—å—é, —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –≤–∏–¥–µ–ª –ø—Ä–æ–≥—Ä–µ—Å—Å –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏.
                edit_interval = max(0.5, float(AUTO_REPLY_STREAM_EDIT_INTERVAL_SECONDS))
                if curr_t - last_update > edit_interval:
                    preview = _build_stream_preview(full_response, max_chars=3600)
                    candidate = preview + " ‚ñå"
                    if _should_emit_stream_edit(last_preview_sent, candidate, min_delta_chars=80):
                        await _safe_stream_edit_text(reply_msg, candidate)
                        last_preview_sent = candidate
                        last_update = curr_t
        except Exception as e:
            logger.error(f"Streaming error occurred: {e}")
            # –ï—Å–ª–∏ —É –Ω–∞—Å —É–∂–µ –µ—Å—Ç—å –∫–∞–∫–æ–π-—Ç–æ —Ç–µ–∫—Å—Ç, –º—ã –Ω–µ –ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É –¥–∞–ª—å—à–µ,
            # —á—Ç–æ–±—ã –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø–æ–ª—É—á–∏–ª —Ö–æ—Ç—è –±—ã —á–∞—Å—Ç—å –æ—Ç–≤–µ—Ç–∞.
            if not full_response:
                raise e
            else:
                 full_response += f"\n\n‚ö†Ô∏è [–°—Ç—Ä–∏–º –ø—Ä–µ—Ä–≤–∞–Ω: {e}]"

    try:
        await asyncio.wait_for(run_streaming(), timeout=AUTO_REPLY_TIMEOUT_SECONDS)
    except asyncio.TimeoutError:
        logger.warning(f"Timeout reaching model for chat {message.chat.id}")
        if not full_response:
             await reply_msg.edit_text("‚åõ **–í—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è –∏—Å—Ç–µ–∫–ª–æ.** –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â–µ —Ä–∞–∑.")
             return
    except Exception as e:
        logger.error(f"Auto-reply critical failure: {e}")
        if not full_response:
            await reply_msg.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")
            return

    if (
        full_response
        and bool(ai_runtime and ai_runtime.continue_on_incomplete_enabled)
        and _looks_incomplete_response(full_response)
    ):
        if ai_runtime:
            current = ai_runtime.get_context_snapshot(message.chat.id)
            current["continue_on_incomplete_triggered"] = True
            current["updated_at"] = int(time.time())
            ai_runtime.set_context_snapshot(message.chat.id, current)
        try:
            await client.send_chat_action(message.chat.id, action=enums.ChatAction.TYPING)
            continuation_prompt = (
                "–ü—Ä–æ–¥–æ–ª–∂–∏ –ø—Ä–µ–¥—ã–¥—É—â–∏–π –æ—Ç–≤–µ—Ç —Å –º–µ—Å—Ç–∞ –æ–±—Ä—ã–≤–∞. "
                "–ù–µ –ø–æ–≤—Ç–æ—Ä—è–π —É–∂–µ –Ω–∞–ø–∏—Å–∞–Ω–Ω–æ–µ. "
                "–ï—Å–ª–∏ –±—ã–ª –æ–±–µ—â–∞–Ω –ø–ª–∞–Ω/—Å–ø–∏—Å–æ–∫ ‚Äî –¥–æ–ø–∏—à–∏ –µ–≥–æ –ø–æ–ª–Ω–æ—Å—Ç—å—é –∏ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω–æ."
            )
            continuation_context = list(context or []) + [
                {"role": "assistant", "text": str(full_response)},
            ]
            continuation = ""
            async for part in router.route_stream(
                prompt=continuation_prompt,
                task_type="chat",
                context=continuation_context,
                chat_type=message.chat.type.name.lower(),
                is_owner=is_owner_sender,
            ):
                continuation += part
            continuation = _sanitize_model_output(continuation, router)
            if continuation:
                full_response = f"{full_response.rstrip()}\n\n{continuation.lstrip()}"
                if ai_runtime:
                    current = ai_runtime.get_context_snapshot(message.chat.id)
                    current["continue_on_incomplete_applied"] = True
                    current["updated_at"] = int(time.time())
                    ai_runtime.set_context_snapshot(message.chat.id, current)
        except Exception as continue_exc:
            logger.debug(
                "–ê–≤—Ç–æ–¥–æ–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –ø—Ä–æ–ø—É—â–µ–Ω–æ –ø–æ—Å–ª–µ –æ—à–∏–±–∫–∏",
                chat_id=message.chat.id,
                error=str(continue_exc),
            )

    persisted_response_text = _sanitize_model_output(full_response, router)
    if full_response:
        logger.debug(
            "auto_reply: –ø–æ–ª—É—á–µ–Ω –æ—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏",
            chat_id=message.chat.id,
            message_id=message.id,
            response_chars=len(full_response or ""),
        )
        clean_display_text = _sanitize_model_output(full_response, router)
        clean_display_text, removed_service_phrases = _drop_service_busy_phrases(clean_display_text)
        clean_display_text, removed_tool_artifacts = _drop_tool_artifact_blocks(clean_display_text)
        clean_display_text, removed_english_scaffold = _drop_english_scaffold_when_russian_expected(
            clean_display_text,
            prefer_russian=prefer_russian_response,
            min_paragraph_len=160,
        )
        clean_display_text, removed_repeated_lines = _collapse_repeated_lines(
            clean_display_text,
            max_consecutive_repeats=2,
        )
        clean_display_text, removed_repeats = _collapse_repeated_paragraphs(
            clean_display_text,
            max_consecutive_repeats=2,
        )
        clean_display_text, removed_nonconsecutive_repeats = _dedupe_repeated_long_paragraphs(
            clean_display_text,
            min_normalized_len=140,
            max_occurrences=1,
        )
        clean_display_text, corrected_vision_consistency = _enforce_vision_route_consistency(
            clean_display_text,
            vision_route_meta,
        )
        clean_display_text, trimmed_numbered = _cap_numbered_list_items(
            clean_display_text,
            max_items=AUTO_REPLY_MAX_NUMBERED_LIST_ITEMS,
        )
        clean_display_text, removed_numbered_duplicates = _prune_repetitive_numbered_items(
            clean_display_text,
            max_same_body=2,
        )
        if any(
            [
                removed_repeats,
                removed_repeated_lines,
                removed_nonconsecutive_repeats,
                corrected_vision_consistency,
                removed_service_phrases,
                removed_tool_artifacts,
                removed_english_scaffold,
                removed_numbered_duplicates,
            ]
        ):
            logger.info(
                "auto_reply: –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –∞–≤—Ç–æ–æ—á–∏—Å—Ç–∫–∞ –æ—Ç–≤–µ—Ç–∞",
                chat_id=message.chat.id,
                message_id=message.id,
                removed_repeats=bool(removed_repeats),
                removed_repeated_lines=bool(removed_repeated_lines),
                removed_nonconsecutive_repeats=bool(removed_nonconsecutive_repeats),
                corrected_vision_consistency=bool(corrected_vision_consistency),
                removed_service_phrases=bool(removed_service_phrases),
                removed_tool_artifacts=bool(removed_tool_artifacts),
                removed_english_scaffold=bool(removed_english_scaffold),
                removed_numbered_duplicates=bool(removed_numbered_duplicates),
            )
        if _looks_like_internal_dump(clean_display_text):
            clean_display_text = (
                "‚ö†Ô∏è –ü–æ–π–º–∞–ª –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–π —Å–ª—É–∂–µ–±–Ω—ã–π –≤—ã–≤–æ–¥ –º–æ–¥–µ–ª–∏ –∏ —Å–∫—Ä—ã–ª –µ–≥–æ.\n"
                "–ü–æ–ø—Ä–æ–±—É–π –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –∑–∞–ø—Ä–æ—Å –∫–æ—Ä–æ—á–µ, –±–µ–∑ –ø–µ—Ä–µ—Å—ã–ª–∫–∏ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–≥–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞."
            )
        clean_display_text, runtime_error_rewritten = _normalize_runtime_error_message_for_user(
            clean_display_text,
            router,
        )
        if runtime_error_rewritten:
            logger.warning(
                "auto_reply: runtime –æ—à–∏–±–∫–∞ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–∞ –≤ user-facing fallback",
                chat_id=message.chat.id,
                message_id=message.id,
            )
        clean_display_text, response_trimmed = _clamp_auto_reply_text(
            clean_display_text,
            is_private=is_private,
        )
        if response_trimmed:
            logger.warning(
                "auto_reply: –æ—Ç–≤–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –ø–æ –¥–ª–∏–Ω–µ",
                chat_id=message.chat.id,
                message_id=message.id,
                limit_private=AUTO_REPLY_MAX_RESPONSE_CHARS_PRIVATE,
                limit_public=AUTO_REPLY_MAX_RESPONSE_CHARS,
            )
        if trimmed_numbered:
            logger.warning("–û—Ç–≤–µ—Ç –±—ã–ª –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –ø–æ –¥–ª–∏–Ω–µ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞", chat_id=message.chat.id)
        if not clean_display_text:
            clean_display_text = "‚ö†Ô∏è –û—Ç–≤–µ—Ç –æ—á–∏—â–µ–Ω –æ—Ç —Å–ª—É–∂–µ–±–Ω—ã—Ö –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤. –ü–æ–≤—Ç–æ—Ä–∏ –∑–∞–ø—Ä–æ—Å, –µ—Å–ª–∏ –Ω—É–∂–µ–Ω –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç."
        if vision_route_fact_line and vision_route_fact_line not in clean_display_text:
            clean_display_text = f"{vision_route_fact_line}\n\n{clean_display_text}".strip()
        
        # –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–∞—è —Ä–µ–∞–∫—Ü–∏—è: –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å —ç–º–æ–¥–∑–∏, —Å—Ç–∞–≤–∏–º –µ–≥–æ –∫–∞–∫ —Ä–µ–∞–∫—Ü–∏—é
        import re
        emoji_match = re.match(r"^([\U00010000-\U0010ffff])", clean_display_text)
        if emoji_match:
            await set_message_reaction(client, message.chat.id, message.id, emoji_match.group(1))
        
        # –û—Ç–ø—Ä–∞–≤–∫–∞ –æ—Ç–≤–µ—Ç–∞
        MAX_LEN = 3900
        chunks = _split_text_chunks_for_telegram(clean_display_text, max_len=MAX_LEN)
        truncated_for_telegram = len(chunks) > 1
        chunks_sent = 1
        if len(chunks) > 1:
            await _safe_stream_edit_text(reply_msg, chunks[0])
            for idx, chunk in enumerate(chunks[1:], start=2):
                suffix = f"\n\n‚Äî –ß–∞—Å—Ç—å {idx}/{len(chunks)} ‚Äî"
                safe_chunk = chunk
                if len(safe_chunk) + len(suffix) <= MAX_LEN:
                    safe_chunk = f"{safe_chunk}{suffix}"
                await message.reply_text(safe_chunk, parse_mode=None)
            chunks_sent = len(chunks)
        else:
            await _safe_stream_edit_text(reply_msg, clean_display_text)
        persisted_response_text = clean_display_text

        # –ü—Ä–∏–≤—è–∑–∫–∞ –æ—Ç–≤–µ—Ç–∞ –∫ –º–∞—Ä—à—Ä—É—Ç—É –¥–ª—è weak reaction feedback.
        if reaction_engine:
            try:
                last_route = router.get_last_route() if hasattr(router, "get_last_route") else {}
                if isinstance(last_route, dict) and last_route:
                    reaction_engine.bind_assistant_message(
                        chat_id=message.chat.id,
                        message_id=reply_msg.id,
                        route=last_route,
                    )
            except Exception as bind_exc:
                logger.debug("–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤—è–∑–∞—Ç—å –æ—Ç–≤–µ—Ç –¥–ª—è reaction learning", error=str(bind_exc))
        
        # TTS Implementation (Perceptor-first, OpenClaw fallback).
        if is_voice_response_needed and (perceptor or (openclaw and hasattr(openclaw, "generate_speech"))):
            error_keywords = [
                "–∏–∑–≤–∏–Ω–∏",
                "–Ω–µ –º–æ–≥—É",
                "–æ—à–∏–±–∫–∞",
                "–Ω–µ —É–¥–∞–ª–æ—Å—å",
                "llm error",
                "not_found",
                "status\": \"not_found\"",
            ]
            if not any(kw in clean_display_text[:100].lower() for kw in error_keywords):
                logger.info(f"üé§ Requesting TTS for chat {message.chat.id}")
                await client.send_chat_action(message.chat.id, action=enums.ChatAction.RECORD_AUDIO)
                
                try:
                    tts_text = _prepare_tts_text(clean_display_text)
                    if not tts_text:
                        logger.warning("‚ö†Ô∏è TTS skipped: empty prepared text", chat_id=message.chat.id)
                        return
                    tts_chunks = _split_tts_chunks(tts_text, max_chars=1100, max_chunks=6)
                    if not tts_chunks:
                        logger.warning("‚ö†Ô∏è TTS skipped: no chunks after split", chat_id=message.chat.id)
                        return

                    sent_parts = 0
                    total_parts = len(tts_chunks)
                    for idx, chunk in enumerate(tts_chunks, start=1):
                        if perceptor:
                            tts_file = await perceptor.speak(chunk)
                        else:
                            tts_file = await _await_if_needed(openclaw.generate_speech(chunk))
                        if not (tts_file and os.path.exists(tts_file)):
                            logger.warning(
                                "‚ö†Ô∏è TTS failed to generate file for chunk",
                                chat_id=message.chat.id,
                                chunk_index=idx,
                                chunk_total=total_parts,
                            )
                            continue

                        caption = (
                            "üó£Ô∏è **Voice Reply**"
                            if total_parts == 1
                            else f"üó£Ô∏è **Voice Reply {idx}/{total_parts}**"
                        )
                        await message.reply_voice(tts_file, caption=caption)
                        sent_parts += 1
                        try:
                            os.remove(tts_file)
                        except Exception:
                            pass

                    if sent_parts == 0:
                        await message.reply_text("üó£Ô∏è *[–û—à–∏–±–∫–∞ –æ–∑–≤—É—á–∫–∏: –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ]*")
                    else:
                        logger.info(
                            "‚úÖ Voice reply sent",
                            chat_id=message.chat.id,
                            parts_sent=sent_parts,
                            parts_total=total_parts,
                        )
                except Exception as tts_exc:
                    logger.error(f"‚ùå TTS Error in ai.py: {tts_exc}")
                    await message.reply_text(f"üó£Ô∏è *[–û—à–∏–±–∫–∞ TTS: {str(tts_exc)[:100]}]*")
            else:
                logger.info("üîá Skipping TTS for error message/refusal.")
    else:
        await reply_msg.edit_text("‚ùå –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")

    # Save Assistant Message
    is_runtime_error_resp = False
    if hasattr(router, "_is_runtime_error_message"):
        is_runtime_error_resp = router._is_runtime_error_message(persisted_response_text)
    elif persisted_response_text.startswith("‚ùå "):
        is_runtime_error_resp = True

    if not is_runtime_error_resp:
        memory.save_message(
            message.chat.id,
            {
                "role": "assistant",
                "text": persisted_response_text,
                "chat_type": chat_type_value,
                "reply_to_author_id": int(user_id or 0),
            },
        )
    else:
        logger.warning(
            "auto_reply: –ø—Ä–æ–ø—É—â–µ–Ω save_message (–æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –æ–± –æ—à–∏–±–∫–µ)",
            chat_id=message.chat.id
        )

    if ai_runtime:
        current = ai_runtime.get_context_snapshot(message.chat.id)
        current["response_length_chars"] = len(persisted_response_text or "")
        current["telegram_truncated"] = bool(locals().get("truncated_for_telegram", False))
        current["telegram_chunks_sent"] = int(locals().get("chunks_sent", 1))
        current["updated_at"] = int(time.time())
        ai_runtime.set_context_snapshot(message.chat.id, current)

    # Optional: –∞–≤—Ç–æ-—Ä–µ–∞–∫—Ü–∏—è –ö—Ä–∞–±–∞ –Ω–∞ –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    if reaction_engine and ai_runtime and ai_runtime.auto_reactions_enabled:
        try:
            if reaction_engine.can_send_auto_reaction(message.chat.id):
                reaction_emoji = reaction_engine.choose_auto_reaction(persisted_response_text, message.chat.id)
                await set_message_reaction(client, message.chat.id, message.id, reaction_emoji)
        except Exception as react_exc:
            logger.debug("Auto reaction skipped", error=str(react_exc))



def register_handlers(app, deps: dict):
    """–†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ—Ç AI-–æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∏."""
    router = deps["router"]
    memory = deps["memory"]
    security = deps["security"]
    agent = deps["agent"]
    rate_limiter = deps["rate_limiter"]
    safe_handler = deps["safe_handler"]
    queue_manager = ChatWorkQueue(
        max_per_chat=AUTO_REPLY_QUEUE_MAX_PER_CHAT,
        max_retries=AUTO_REPLY_QUEUE_MAX_RETRIES,
    )
    reaction_engine = ReactionLearningEngine(
        store_path=os.getenv("REACTION_FEEDBACK_PATH", "artifacts/reaction_feedback.json"),
        enabled=REACTION_LEARNING_ENABLED,
        weight=REACTION_LEARNING_WEIGHT,
        mood_enabled=CHAT_MOOD_ENABLED,
        auto_reactions_enabled=AUTO_REACTIONS_ENABLED,
        auto_reaction_rate_seconds=_timeout_from_env("AUTO_REACTIONS_MIN_INTERVAL_SECONDS", 6),
        mood_window=_timeout_from_env("CHAT_MOOD_WINDOW", 120),
    )
    ai_runtime = AIRuntimeControl(queue_manager=queue_manager, reaction_engine=reaction_engine, router=router)
    deps["ai_runtime"] = ai_runtime
    deps["reaction_engine"] = reaction_engine
    deps["chat_work_queue"] = queue_manager
    forward_burst_buffers: dict[str, dict] = {}

    @app.on_raw_update()
    async def reaction_learning_raw_handler(client, update, users, chats):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ raw updates —Ä–µ–∞–∫—Ü–∏–π –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏—è.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∫–∞–∫ weak-signal –¥–ª—è –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏/—Ç–æ–Ω–∞.
        """
        if not isinstance(update, raw.types.UpdateMessageReactions):
            return
        if not ai_runtime.reaction_learning_enabled:
            return
        try:
            chat_id = int(pyro_utils.get_peer_id(update.peer))
            message_id = int(update.msg_id)
            reactions = getattr(update, "reactions", None)
            if not reactions:
                return

            recent = getattr(reactions, "recent_reactions", None) or []
            for item in recent:
                reaction_obj = getattr(item, "reaction", None)
                emoji = ""
                if isinstance(reaction_obj, raw.types.ReactionEmoji):
                    emoji = str(getattr(reaction_obj, "emoticon", "") or "")
                elif isinstance(reaction_obj, raw.types.ReactionCustomEmoji):
                    emoji = f"custom:{getattr(reaction_obj, 'document_id', '')}"
                if not emoji:
                    continue
                actor_id = int(pyro_utils.get_peer_id(getattr(item, "peer_id", None))) if getattr(item, "peer_id", None) else 0
                reaction_engine.register_reaction(
                    chat_id=chat_id,
                    message_id=message_id,
                    actor_id=actor_id,
                    emoji=emoji,
                    action="added",
                    router=router,
                )
        except Exception as exc:
            logger.debug("Reaction raw update parse skipped", error=str(exc))

    def _extract_prompt_and_confirm_flag(message_text: str) -> tuple[str, bool]:
        """
        –†–∞–∑–±–∏—Ä–∞–µ—Ç –∫–æ–º–∞–Ω–¥—É –∏ –≤—ã–¥–µ–ª—è–µ—Ç:
        - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–π prompt,
        - —Ñ–ª–∞–≥ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–æ—Ä–æ–≥–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ (`--confirm-expensive` / `--confirm` / `confirm`).
        """
        raw = message_text or ""
        try:
            argv = shlex.split(raw)
        except ValueError:
            argv = raw.split()

        if len(argv) < 2:
            return "", False

        confirm_expensive = False
        payload_tokens: list[str] = []
        for token in argv[1:]:
            normalized = token.strip().lower()
            if normalized in {"--confirm-expensive", "--confirm", "confirm"}:
                confirm_expensive = True
                continue
            payload_tokens.append(token)

        prompt = " ".join(payload_tokens).strip()
        return prompt, confirm_expensive

    async def _danger_audit(message: Message, action: str, status: str, details: str = ""):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –æ–ø–∞—Å–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –≤ Saved Messages –∏ –≤–ª–∞–¥–µ–ª—å—Ü—É –¥–ª—è –∞—É–¥–∏—Ç–∞."""
        sender = message.from_user.username if message.from_user else "unknown"
        chat_title = message.chat.title or "private"
        chat_id = message.chat.id
        payload = (
            f"üõ°Ô∏è **Danger Audit**\n"
            f"- action: `{action}`\n"
            f"- status: `{status}`\n"
            f"- sender: `@{sender}`\n"
            f"- chat: `{chat_title}` (`{chat_id}`)\n"
        )
        if details:
            payload += f"- details: `{details[:800]}`\n"
        try:
            await app.send_message("me", payload)
        except Exception:
            pass
        try:
            await app.send_message("@p0lrd", payload)
        except Exception:
            pass

    # --- !think: Reasoning Mode ---
    @app.on_message(filters.command("think", prefixes="!"))
    @safe_handler
    async def think_command(client, message: Message):
        """Reasoning Mode: !think <–∑–∞–ø—Ä–æ—Å>"""
        prompt, confirm_expensive = _extract_prompt_and_confirm_flag(message.text or "")
        if not prompt:
            await message.reply_text(
                "üß† –û —á–µ–º –º–Ω–µ –ø–æ–¥—É–º–∞—Ç—å? `!think –ö–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–≤–∞–Ω—Ç–æ–≤—ã–π –∫–æ–º–ø—å—é—Ç–µ—Ä?`\n"
                "–î–ª—è –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á: –¥–æ–±–∞–≤—å `--confirm-expensive`."
            )
            return

        # notification = await message.reply_text("üß† **–†–∞–∑–º—ã—à–ª—è—é...** (Reasoning Mode)") # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–µ–µ

        context = memory.get_token_aware_context(message.chat.id, max_tokens=10000)

        full_response = ""
        last_update = 0
        last_preview_sent = ""
        
        reply_msg = await message.reply_text("ü§î **–†–∞–∑–º—ã—à–ª—è—é...**")

        try:
            stream_used = False
            route_stream = getattr(router, "route_stream", None)
            if callable(route_stream):
                try:
                    stream_candidate = route_stream(
                        prompt=prompt,
                        task_type="reasoning",
                        context=context,
                        chat_type=message.chat.type.name.lower(),
                        is_owner=is_owner(message),
                        confirm_expensive=confirm_expensive,
                    )
                    if hasattr(stream_candidate, "__aiter__"):
                        stream_used = True
                        async for chunk in stream_candidate:
                            full_response += chunk
                            curr_t = time.time()
                            if curr_t - last_update > 2.0:
                                preview = _build_stream_preview(full_response, max_chars=3600)
                                candidate = preview + " ‚ñå"
                                if _should_emit_stream_edit(last_preview_sent, candidate, min_delta_chars=120):
                                    await _safe_stream_edit_text(reply_msg, candidate)
                                    last_preview_sent = candidate
                                    last_update = curr_t
                        if not full_response:
                            stream_used = False
                except Exception as stream_exc:
                    logger.debug("think_command: fallback –Ω–∞ route_query –ø–æ—Å–ª–µ stream –æ—à–∏–±–∫–∏", error=str(stream_exc))
                    stream_used = False

            if not stream_used:
                # Legacy fallback –¥–ª—è —Ç–µ—Å—Ç–æ–≤/–º–æ–∫–æ–≤ –±–µ–∑ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ async stream API.
                full_response = await router.route_query(
                    prompt=prompt,
                    task_type="reasoning",
                    context=context,
                    chat_type=message.chat.type.name.lower(),
                    is_owner=is_owner(message),
                    confirm_expensive=confirm_expensive,
                )

            await reply_msg.edit_text(_sanitize_model_output(full_response, router))
        except asyncio.TimeoutError: # Moved timeout handling here
            full_response = (
                f"‚è≥ –†–∞–∑–º—ã—à–ª–µ–Ω–∏–µ –∑–∞–Ω—è–ª–æ —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (>{THINK_TIMEOUT_SECONDS}—Å). "
                "–ü–æ–ø—Ä–æ–±—É–π —É–ø—Ä–æ—Å—Ç–∏—Ç—å –∑–∞–ø—Ä–æ—Å."
            )
        memory.save_message(message.chat.id, {"role": "assistant", "text": _sanitize_model_output(full_response, router)})

    # --- !smart: –ê–≥–µ–Ω—Ç–Ω—ã–π —Ü–∏–∫–ª (Phase 6) ---
    @app.on_message(filters.command("smart", prefixes="!"))
    @safe_handler
    async def smart_command(client, message: Message):
        """Agent Workflow: !smart <–∑–∞–¥–∞—á–∞>"""
        if not security.can_execute_command(
            message.from_user.username, message.from_user.id, "user"
        ):
            return

        prompt, confirm_expensive = _extract_prompt_and_confirm_flag(message.text or "")
        if not prompt:
            await message.reply_text(
                "üß† –û–ø–∏—à–∏ —Å–ª–æ–∂–Ω—É—é –∑–∞–¥–∞—á—É: "
                "`!smart –†–∞–∑—Ä–∞–±–æ—Ç–∞–π –ø–ª–∞–Ω –ø–µ—Ä–µ–µ–∑–¥–∞ –≤ –¥—Ä—É–≥—É—é —Å—Ç—Ä–∞–Ω—É`"
            )
            return

        # Confirm-step –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ –¥–æ—Ä–æ–≥–∏—Ö –∫—Ä–∏—Ç–∏—á–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤.
        require_confirm = bool(getattr(router, "require_confirm_expensive", False))
        profile = (
            router.classify_task_profile(prompt, "reasoning")
            if hasattr(router, "classify_task_profile")
            else "chat"
        )
        is_critical = profile in {"security", "infra", "review"}
        if require_confirm and is_critical and not confirm_expensive:
            await message.reply_text(
                "‚ö†Ô∏è –î–ª—è –∫—Ä–∏—Ç–∏—á–Ω–æ–π –∑–∞–¥–∞—á–∏ –Ω—É–∂–µ–Ω confirm-step.\n"
                "–ü–æ–≤—Ç–æ—Ä–∏ —Å `!smart --confirm-expensive <–∑–∞–¥–∞—á–∞>`."
            )
            return

        notification = await message.reply_text("üïµÔ∏è **Agent:** –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –≤–æ—Ä–∫—Ñ–ª–æ—É...")

        result = await agent.solve_complex_task(prompt, message.chat.id)

        await notification.edit_text(result)
        memory.save_message(message.chat.id, {"role": "assistant", "text": result})

    @app.on_message(filters.command("bg", prefixes="!"))
    @safe_handler
    async def bg_command(client, message: Message):
        """Background Task: !bg <–∑–∞–¥–∞—á–∞>"""
        if not is_authorized(message): return

        if len(message.command) < 2:
            await message.reply_text("‚è≥ –û–ø–∏—à–∏ —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É: `!bg –ø—Ä–æ–≤–µ–¥–∏ –≥–ª—É–±–æ–∫–æ–µ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –ø–æ X`")
            return

        prompt = message.text.split(" ", 1)[1]
        task_queue = deps["task_queue"]
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ—Ä—É—Ç–∏–Ω—É –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        coro = agent.solve_complex_task(prompt, message.chat.id)
        
        task_id = await task_queue.enqueue(f"Agent solve: {prompt[:30]}", message.chat.id, coro)
        
        await message.reply_text(f"üöÄ –ó–∞–¥–∞—á–∞ –∑–∞–ø—É—â–µ–Ω–∞ –≤ —Ñ–æ–Ω–µ!\nID: `{task_id}`\n–Ø –ø—Ä–∏—à–ª—é —É–≤–µ–¥–æ–º–ª–µ–Ω–∏–µ, –∫–æ–≥–¥–∞ –∑–∞–∫–æ–Ω—á—É.")

    # --- !swarm: Swarm Intelligence (Phase 10) ---
    @app.on_message(filters.command("swarm", prefixes="!"))
    @safe_handler
    async def swarm_command(client, message: Message):
        """Swarm Intelligence: !swarm <–∑–∞–ø—Ä–æ—Å>"""
        if not is_authorized(message): return
        
        if len(message.command) < 2:
            await message.reply_text("üêù –û–ø–∏—à–∏ –∑–∞–¥–∞—á—É –¥–ª—è –†–æ—è: `!swarm –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ä—ã–Ω–æ–∫ –∏ –ø–æ–∏—â–∏ –Ω–æ–≤–æ—Å—Ç–∏`")
            return

        query = message.text.split(" ", 1)[1]
        notification = await message.reply_text("üêù **Swarm Intelligence:** –ê–∫—Ç–∏–≤–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–æ–≤...")

        tools = deps["tools"]
        # –í—ã–∑—ã–≤–∞–µ–º –∞–≤—Ç–æ–Ω–æ–º–Ω–æ–µ —Ä–µ—à–µ–Ω–∏–µ (–≤–∫–ª—é—á–∞—è –∫–æ–Ω—Å–∏–ª–∏—É–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ç—Ä–∏–≥–≥–µ—Ä)
        result = await tools.swarm.autonomous_decision(query)
        
        if result is None:
             # Fallback –Ω–∞ –æ–±—ã—á–Ω—ã–π –æ—Ç–≤–µ—Ç –µ—Å–ª–∏ —Ä–æ–π –Ω–µ –∑–Ω–∞–µ—Ç —á—Ç–æ –¥–µ–ª–∞—Ç—å
             result = await router.route_query(
                 prompt=query, 
                 task_type='chat',
                 chat_type=message.chat.type.name.lower(),
                 is_owner=is_owner(message)
             )

        await notification.edit_text(result)
        memory.save_message(message.chat.id, {"role": "assistant", "text": result})

    # --- !code: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞ ---
    @app.on_message(filters.command("code", prefixes="!"))
    @safe_handler
    async def code_command(client, message: Message):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–¥–∞: !code <–æ–ø–∏—Å–∞–Ω–∏–µ>"""
        prompt, confirm_expensive, raw_code_mode = _extract_code_prompt_flags(message.text or "")
        if not prompt:
            await message.reply_text(
                "üíª –û–ø–∏—à–∏ –∑–∞–¥–∞—á—É: `!code –ù–∞–ø–∏—à–∏ FastAPI —Å–µ—Ä–≤–µ—Ä —Å —ç–Ω–¥–ø–æ–∏–Ω—Ç–æ–º /health`\n"
                "–§–ª–∞–≥–∏: `--confirm-expensive`, `--raw-code`"
            )
            return

        notification = await message.reply_text("üíª **–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∫–æ–¥...**")

        if raw_code_mode:
            code_prompt = (
                f"–ù–∞–ø–∏—à–∏ –∫–æ–¥ –ø–æ –∑–∞–ø—Ä–æ—Å—É: {prompt}\n\n"
                "–§–æ—Ä–º–∞—Ç: —Ç–æ–ª—å–∫–æ –∫–æ–¥ —Å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è–º–∏, –±–µ–∑ –ª–∏—à–Ω–∏—Ö –æ–±—ä—è—Å–Ω–µ–Ω–∏–π. "
                "–Ø–∑—ã–∫ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞."
            )
        else:
            code_prompt = _build_safe_code_prompt(
                prompt=prompt,
                strict_mode=_is_critical_code_request(prompt),
            )

        response = await router.route_query(
            prompt=code_prompt,
            task_type="coding",
            chat_type=message.chat.type.name.lower(),
            is_owner=is_owner(message),
            confirm_expensive=confirm_expensive,
        )

        await notification.edit_text(response)

    # --- !learn / !remember: –û–±—É—á–µ–Ω–∏–µ RAG ---
    @app.on_message(filters.command(["learn", "remember"], prefixes="!"))
    @safe_handler
    async def learn_command(client, message: Message):
        """–û–±—É—á–µ–Ω–∏–µ: !learn <–∑–∞–ø—Ä–æ—Å –∏–ª–∏ —Ñ–∞–π–ª –∏–ª–∏ —Å—Å—ã–ª–∫–∞>"""
        browser_agent = deps.get("browser_agent")
        openclaw = deps.get("openclaw_client")
        
        # 1. –ï—Å–ª–∏ –µ—Å—Ç—å —Ñ–∞–π–ª
        if message.document:
            file_name = message.document.file_name.lower()
            if not (file_name.endswith(('.txt', '.pdf', '.md'))):
                await message.reply_text("‚ùå –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ .txt, .pdf –∏ .md")
                return
            
            notif = await message.reply_text(f"üìÑ –ß–∏—Ç–∞—é —Ñ–∞–π–ª `{file_name}`...")
            path = await message.download()
            
            content = ""
            if file_name.endswith('.pdf'):
                try:
                    import PyPDF2
                    with open(path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        content = "\n".join([page.extract_text() for page in reader.pages])
                except Exception as e:
                    content = f"Error reading PDF: {e}"
            else:
                with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
            
            os.remove(path)
            
            if len(content) < 10:
                await notif.edit_text("‚ùå –§–∞–π–ª –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —á–∏—Ç–∞–µ—Ç—Å—è.")
                return
            
            doc_id = router.rag.add_document(
                text=content,
                metadata={"source": "file", "filename": file_name},
                category="document"
            )
            await notif.edit_text(f"üß† **–§–∞–π–ª –∏–∑—É—á–µ–Ω!**\nID: `{doc_id}`\n–°–∏–º–≤–æ–ª–æ–≤: {len(content)}")
            return

        # 2. –ï—Å–ª–∏ –µ—Å—Ç—å —Å—Å—ã–ª–∫–∞
        if len(message.command) > 1 and message.command[1].startswith('http'):
            url = message.command[1]
            notif = await message.reply_text(f"üåê –ò–∑—É—á–∞—é —Å—Å—ã–ª–∫—É: `{url}`...")
            content_text = ""
            title = url

            # OpenClaw-first: web_fetch, –ª–æ–∫–∞–ª—å–Ω—ã–π –±—Ä–∞—É–∑–µ—Ä —Ç–æ–ª—å–∫–æ fallback.
            if openclaw:
                fetched = await openclaw.invoke_tool("web_fetch", {"url": url})
                if not fetched.get("error"):
                    try:
                        content_text = fetched.get("content", [{}])[0].get("text", "")[:20000]
                        title = fetched.get("details", {}).get("title", title)
                    except Exception:
                        content_text = ""

            if not content_text and browser_agent:
                res = await browser_agent.browse(url)
                if "error" not in res:
                    content_text = res.get("content", "")
                    title = res.get("title", title)

            if not content_text:
                await notif.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã.")
                return

            doc_id = router.rag.add_document(
                text=content_text,
                metadata={"source": "web", "url": url, "title": title},
                category="web"
            )
            await notif.edit_text(f"üß† **–°—Å—ã–ª–∫–∞ –∏–∑—É—á–µ–Ω–∞!**\n–ó–∞–≥–æ–ª–æ–≤–æ–∫: `{title}`\nID: `{doc_id}`")
            return

        # 3. –û–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
        if len(message.command) < 2:
            await message.reply_text("üß† –ß–µ–º—É –Ω–∞—É—á–∏—Ç—å? `!learn Python –±—ã–ª —Å–æ–∑–¥–∞–Ω –ì–≤–∏–¥–æ –≤–∞–Ω –†–æ—Å—Å—É–º–æ–º` –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å —Ñ–∞–π–ª/—Å—Å—ã–ª–∫—É.")
            return

        fact = message.text.split(" ", 1)[1]
        doc_id = router.rag.add_document(
            text=fact,
            metadata={
                "source": "user_learn",
                "user": message.from_user.username if message.from_user else "unknown",
                "chat_id": str(message.chat.id),
            },
            category="learning",
        )
        await message.reply_text(f"üß† **–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ø–∞–º—è—Ç—å.** ID: `{doc_id}`")

    @app.on_message(filters.command("clone", prefixes="!"))
    @safe_handler
    async def clone_command(client, message: Message):
        """Persona Cloning: !clone [name] (Owner Only)"""
        if not is_owner(message):
            return
        
        name = message.command[1] if len(message.command) > 1 else "Digital Twin"
        notif = await message.reply_text(f"üëØ **–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é –∫–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –ª–∏—á–Ω–æ—Å—Ç–∏ `{name}`...**")
        
        # 1. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –∏–∑ RAG (—Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
        await notif.edit_text("üîé **–®–∞–≥ 1/3:** –°–æ–±–∏—Ä–∞—é –æ–±—Ä–∞–∑—Ü—ã —Ç–≤–æ–µ–≥–æ —Å—Ç–∏–ª—è –∏–∑ –ø–∞–º—è—Ç–∏...")
        query = f"—Å–æ–æ–±—â–µ–Ω–∏—è –æ—Ç @{message.from_user.username}"
        samples = router.rag.query(query, n_results=15, category="learning")
        
        if not samples or len(samples) < 50:
            # Fallback: –ø—Ä–æ–±—É–µ–º –∏—Å–∫–∞—Ç—å –≤ –æ–±—â–µ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
            samples = router.rag.query(query, n_results=15)

        if not samples or len(samples) < 50:
             await notif.edit_text("‚ùå **–û—à–∏–±–∫–∞:** –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –≤ –ø–∞–º—è—Ç–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ç–∏–ª—è. –ü–æ–æ–±—â–∞–π—Å—è —Å–æ –º–Ω–æ–π –ø–æ–±–æ–ª—å—à–µ!")
             return

        # 2. –ê–Ω–∞–ª–∏–∑ —Å—Ç–∏–ª—è —á–µ—Ä–µ–∑ LLM
        await notif.edit_text("üìä **–®–∞–≥ 2/3:** –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –ø–∞—Ç—Ç–µ—Ä–Ω—ã —Ä–µ—á–∏ –∏ –ª–∏–Ω–≥–≤–∏—Å—Ç–∏—á–µ—Å–∫–∏–π –ø—Ä–æ—Ñ–∏–ª—å...")
        analysis_prompt = (
            f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç—Ç–∏—Ö –ø—Ä–∏–º–µ—Ä–æ–≤:\n\n{samples}\n\n"
            "–¢–≤–æ—è –∑–∞–¥–∞—á–∞: –°–æ—Å—Ç–∞–≤–∏—Ç—å –∫—Ä–∞—Ç–∫–∏–π 'System Prompt' (–Ω–∞ —Ä—É—Å—Å–∫–æ–º), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª–∏—Ç –¥—Ä—É–≥–æ–π LLM "
            f"–∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å —ç—Ç–æ–≥–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –ù–∞–∑–æ–≤–∏ –µ–≥–æ '{name}'. "
            "–£—á—Ç–∏: —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –ª—é–±–∏–º—ã–µ —Å–ª–æ–≤–∞, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —ç–º–æ–¥–∑–∏, –¥–ª–∏–Ω—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —É—Ä–æ–≤–µ–Ω—å —Ñ–æ—Ä–º–∞–ª—å–Ω–æ—Å—Ç–∏. "
            "–û—Ç–≤–µ—Ç—å –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç–æ–º –ø—Ä–æ–º–ø—Ç–∞, –Ω–∞—á–∏–Ω–∞—é—â–∏–º—Å—è —Å '–¢—ã ‚Äî —Ü–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫...'"
        )
        
        custom_prompt = await router.route_query(
            prompt=analysis_prompt,
            task_type="chat",
            is_owner=True
        )

        # 3. –†–µ–≥–∏—Å—Ç—Ä–∞—Ü–∏—è –ª–∏—á–Ω–æ—Å—Ç–∏
        await notif.edit_text("üíæ **–®–∞–≥ 3/3:** –°–æ—Ö—Ä–∞–Ω—è—é –Ω–æ–≤—É—é –ª–∏—á–Ω–æ—Å—Ç—å –≤ —è–¥—Ä–æ...")
        persona_manager = deps["persona_manager"]
        pid = f"clone_{name.lower().replace(' ', '_')}"
        persona_manager.add_custom_persona(
            pid=pid,
            name=f"–ö–ª–æ–Ω: {name}",
            prompt=custom_prompt,
            desc=f"–¶–∏—Ñ—Ä–æ–≤–æ–π –¥–≤–æ–π–Ω–∏–∫, —Å–æ–∑–¥–∞–Ω–Ω—ã–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ @{message.from_user.username}"
        )
        
        await notif.edit_text(
            f"‚úÖ **–ö–ª–æ–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!**\n\n"
            f"üÜî ID: `{pid}`\n"
            f"üé≠ –ò–º—è: `–ö–ª–æ–Ω: {name}`\n\n"
            f"–ß—Ç–æ–±—ã –∞–∫—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å, –≤–≤–µ–¥–∏: `!persona set {pid}`"
        )

    # --- !rag: –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏ –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π ---
    @app.on_message(filters.command(["rag", "search"], prefixes="!"))
    @safe_handler
    async def rag_command(client, message: Message):
        """–ò–Ω—Ñ–æ –∏ –ø–æ–∏—Å–∫ –ø–æ RAG: !rag [–∑–∞–ø—Ä–æ—Å]"""
        if len(message.command) < 2:
            report = router.rag.format_stats_report()
            await message.reply_text(report)
            return

        query = message.text.split(" ", 1)[1]
        results = router.rag.query_with_scores(query, n_results=3)
        
        if not results:
            await message.reply_text("üîé –ù–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
            return
        
        resp = f"üîé **–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É: `{query}`**\n\n"
        for i, res in enumerate(results, 1):
            expired = "‚ö†Ô∏è (–£—Å—Ç–∞—Ä–µ–ª–æ)" if res['expired'] else ""
            resp += f"{i}. [{res['category']}] Score: {res['score']} {expired}\n"
            resp += f"_{res['text'][:200]}..._\n\n"
        
        await message.reply_text(resp)

    # --- !forget: –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ ---
    @app.on_message(filters.command("forget", prefixes="!"))
    @safe_handler
    async def forget_command(client, message: Message):
        """–û—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Ç–µ–∫—É—â–µ–≥–æ —á–∞—Ç–∞."""
        if not is_authorized(message): return
        
        memory.clear_history(message.chat.id)
        await message.reply_text("üßπ **–ü–∞–º—è—Ç—å —á–∞—Ç–∞ –æ—á–∏—â–µ–Ω–∞.**")

    # --- !vision: Runtime-–Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ vision ---
    @app.on_message(filters.command("vision", prefixes="!"))
    @safe_handler
    async def vision_command(client, message: Message):
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–æ–∫–∞–ª—å–Ω—ã–º vision-–∫–æ–Ω—Ç—É—Ä–æ–º: !vision local on|off|status|model <id>."""
        if not is_authorized(message):
            return

        perceptor = deps.get("perceptor")
        if not perceptor:
            await message.reply_text("‚ùå Perceptor –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            return

        config_manager = deps.get("config_manager")
        parts = (message.text or "").split()
        args = parts[1:] if len(parts) > 1 else []
        action = (args[0].strip().lower() if args else "status")

        def _status_text() -> str:
            enabled = bool(getattr(perceptor, "local_vision_enabled", False))
            pinned_model = str(getattr(perceptor, "local_vision_model", "") or "").strip()
            resolved_model = ""
            if hasattr(perceptor, "_resolve_local_vision_model"):
                try:
                    resolved_model = str(perceptor._resolve_local_vision_model(router) or "").strip()
                except Exception:
                    resolved_model = pinned_model
            gemini_model = str(getattr(perceptor, "vision_model", "") or "").strip()
            timeout_sec = int(float(getattr(perceptor, "local_vision_timeout_seconds", 90)))
            max_tokens = int(getattr(perceptor, "local_vision_max_tokens", 1200))
            last_meta = {}
            if hasattr(perceptor, "get_last_vision_meta"):
                try:
                    candidate_meta = perceptor.get_last_vision_meta()
                    if isinstance(candidate_meta, dict):
                        last_meta = candidate_meta
                except Exception:
                    last_meta = {}
            last_route = str(last_meta.get("route") or "-").strip()
            last_model = str(last_meta.get("model") or "-").strip()
            last_fallback = bool(last_meta.get("fallback_used"))
            last_error = str(last_meta.get("error") or "").strip()
            last_line = (
                f"‚Ä¢ Last vision route: `{last_route}`\n"
                f"‚Ä¢ Last vision model: `{last_model}`\n"
                f"‚Ä¢ Last fallback used: `{'YES' if last_fallback else 'NO'}`\n"
            )
            if last_error:
                last_line += f"‚Ä¢ Last vision error: `{last_error[:140]}`\n"
            return (
                "**üëÅÔ∏è Vision Runtime:**\n\n"
                f"‚Ä¢ Local vision: `{'ON' if enabled else 'OFF'}`\n"
                f"‚Ä¢ Local model (pinned): `{pinned_model or '-'}`\n"
                f"‚Ä¢ Local model (resolved): `{resolved_model or '-'}`\n"
                f"‚Ä¢ Local timeout: `{timeout_sec}s`\n"
                f"‚Ä¢ Local max tokens: `{max_tokens}`\n"
                f"‚Ä¢ Gemini fallback model: `{gemini_model or '-'}`\n"
                f"{last_line}\n"
                "–ö–æ–º–∞–Ω–¥—ã:\n"
                "`!vision status`\n"
                "`!vision local on`\n"
                "`!vision local off`\n"
                "`!vision model <lm_studio_model_id>`"
            )

        if action in {"status", "show"}:
            await message.reply_text(_status_text())
            return

        if action == "local":
            if len(args) < 2 or args[1].strip().lower() not in {"on", "off"}:
                await message.reply_text("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç: `!vision local on` –∏–ª–∏ `!vision local off`")
                return
            enabled = args[1].strip().lower() == "on"
            perceptor.local_vision_enabled = enabled
            os.environ["LOCAL_VISION_ENABLED"] = "1" if enabled else "0"
            if config_manager:
                try:
                    config_manager.set("LOCAL_VISION_ENABLED", "1" if enabled else "0")
                except Exception:
                    pass
            await message.reply_text(
                f"‚úÖ Local vision: `{'ON' if enabled else 'OFF'}`\n"
                "_–ò–∑–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ runtime. –î–ª—è –ø–æ—Å—Ç–æ—è–Ω–Ω–æ–≥–æ —Ä–µ–∂–∏–º–∞ —É–∂–µ –∑–∞–ø–∏—Å–∞–Ω–æ –≤ config (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω)._"
            )
            return

        if action == "model":
            if len(args) < 2:
                await message.reply_text("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç: `!vision model <lm_studio_model_id>`")
                return
            model_id = " ".join(args[1:]).strip()
            perceptor.local_vision_model = model_id
            os.environ["LOCAL_VISION_MODEL"] = model_id
            if config_manager:
                try:
                    config_manager.set("LOCAL_VISION_MODEL", model_id)
                except Exception:
                    pass
            await message.reply_text(
                f"‚úÖ Local vision model –∑–∞–∫—Ä–µ–ø–ª—ë–Ω: `{model_id}`\n"
                "_–°–æ–≤–µ—Ç: –ø—Ä–æ–≤–µ—Ä—å —Ç–æ—á–Ω—ã–π id —á–µ—Ä–µ–∑ `!model scan`._"
            )
            return

        await message.reply_text("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç: `!vision status|local on|local off|model <lm_studio_model_id>`")
        return

    # --- !img / !draw: –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π ---
    @app.on_message(filters.command(["img", "draw"], prefixes="!"))
    @safe_handler
    async def img_command(client, message: Message):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: !img <–æ–ø–∏—Å–∞–Ω–∏–µ> (local/cloud + –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏)."""
        if not is_authorized(message): return

        image_gen = deps.get("image_gen")
        if not image_gen:
            await message.reply_text("‚ùå –û—à–∏–±–∫–∞: Image Manager –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
            return

        try:
            tokens = shlex.split(message.text or "")
        except ValueError:
            tokens = (message.text or "").split()

        args = tokens[1:] if len(tokens) > 1 else []
        if not args:
            await message.reply_text(
                "üé® –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ:\n"
                "`!img <–ø—Ä–æ–º–ø—Ç>`\n"
                "`!img --model <alias> <–ø—Ä–æ–º–ø—Ç>`\n"
                "`!img --local <–ø—Ä–æ–º–ø—Ç>` –∏–ª–∏ `!img --cloud <–ø—Ä–æ–º–ø—Ç>`\n"
                "`!img models` ‚Äî —Å–ø–∏—Å–æ–∫ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–æ–≤\n"
                "`!img cost [alias]` ‚Äî –æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å\n"
                "`!img health` ‚Äî –ø—Ä–æ–≤–µ—Ä–∏—Ç—å local/cloud backend\n"
                "`!img default show|local <alias>|cloud <alias>|mode local|cloud|auto`"
            )
            return

        head = args[0].strip().lower()
        if head == "health":
            rows = await image_gen.list_models()
            local_ok = any(r.get("channel") == "local" and r.get("available") for r in rows)
            cloud_ok = any(r.get("channel") == "cloud" and r.get("available") for r in rows)
            defaults = image_gen.get_defaults() if hasattr(image_gen, "get_defaults") else {}
            await message.reply_text(
                "**ü©∫ Image Health:**\n\n"
                f"‚Ä¢ Local backend: {'üü¢' if local_ok else 'üî¥'}\n"
                f"‚Ä¢ Cloud backend: {'üü¢' if cloud_ok else 'üî¥'}\n"
                f"‚Ä¢ Default local: `{defaults.get('default_local_alias', '-')}`\n"
                f"‚Ä¢ Default cloud: `{defaults.get('default_cloud_alias', '-')}`\n"
                f"‚Ä¢ Prefer local: `{defaults.get('prefer_local', '-')}`"
            )
            return

        if head == "default":
            if not hasattr(image_gen, "set_default_alias") or not hasattr(image_gen, "set_prefer_mode"):
                await message.reply_text("‚ö†Ô∏è –í —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ image manager –Ω–µ—Ç runtime-–Ω–∞—Å—Ç—Ä–æ–µ–∫ –¥–µ—Ñ–æ–ª—Ç–æ–≤.")
                return

            if len(args) < 2 or args[1].strip().lower() == "show":
                defaults = image_gen.get_defaults() if hasattr(image_gen, "get_defaults") else {}
                await message.reply_text(
                    "**üéØ Image Defaults:**\n\n"
                    f"‚Ä¢ Local: `{defaults.get('default_local_alias', '-')}`\n"
                    f"‚Ä¢ Cloud: `{defaults.get('default_cloud_alias', '-')}`\n"
                    f"‚Ä¢ Prefer local: `{defaults.get('prefer_local', '-')}`"
                )
                return

            action = args[1].strip().lower()
            config_manager = deps.get("config_manager")

            if action in {"local", "cloud"}:
                if len(args) < 3:
                    await message.reply_text("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç: `!img default local <alias>` –∏–ª–∏ `!img default cloud <alias>`")
                    return
                alias = args[2].strip()
                result = image_gen.set_default_alias(action, alias)
                if not result.get("ok"):
                    await message.reply_text(f"‚ùå {result.get('error')}")
                    return
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –≤ config.yaml, —á—Ç–æ–±—ã –ø–µ—Ä–µ–∂–∏–≤–∞–ª–æ —Ä–µ—Å—Ç–∞—Ä—Ç.
                if config_manager:
                    key = "IMAGE_DEFAULT_LOCAL_MODEL" if action == "local" else "IMAGE_DEFAULT_CLOUD_MODEL"
                    try:
                        config_manager.set(key, alias)
                    except Exception:
                        pass
                await message.reply_text(
                    f"‚úÖ Default `{action}` model –∑–∞–∫—Ä–µ–ø–ª—ë–Ω: `{alias}`\n"
                    f"–¢–µ–ø–µ—Ä—å: local=`{result.get('default_local_alias')}`, cloud=`{result.get('default_cloud_alias')}`"
                )
                return

            if action == "mode":
                if len(args) < 3:
                    await message.reply_text("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç: `!img default mode local|cloud|auto`")
                    return
                mode = args[2].strip().lower()
                result = image_gen.set_prefer_mode(mode)
                if not result.get("ok"):
                    await message.reply_text(f"‚ùå {result.get('error')}")
                    return
                if config_manager:
                    prefer_local = "1" if result.get("prefer_local") else "0"
                    try:
                        config_manager.set("IMAGE_PREFER_LOCAL", prefer_local)
                    except Exception:
                        pass
                await message.reply_text(
                    f"‚úÖ Image mode: `{mode}` | prefer_local=`{result.get('prefer_local')}`"
                )
                return

            await message.reply_text("‚ö†Ô∏è –§–æ—Ä–º–∞—Ç: `!img default show|local <alias>|cloud <alias>|mode local|cloud|auto`")
            return

        if head in {"models", "list"}:
            if not hasattr(image_gen, "list_models"):
                await message.reply_text("‚ö†Ô∏è –í —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ image manager –Ω–µ—Ç –∫–∞—Ç–∞–ª–æ–≥–∞ –º–æ–¥–µ–ª–µ–π.")
                return
            rows = await image_gen.list_models()
            lines = ["**üé® Image Models:**", ""]
            defaults = image_gen.get_defaults() if hasattr(image_gen, "get_defaults") else {}
            def_local = defaults.get("default_local_alias")
            def_cloud = defaults.get("default_cloud_alias")
            for row in rows:
                icon = "üü¢" if row.get("available") else "üî¥"
                cost = row.get("cost_per_image_usd")
                cost_text = f"~${cost}/img" if cost is not None else "n/a"
                reason = f" ({row.get('reason')})" if row.get("reason") else ""
                alias = row.get("alias")
                marks = []
                if alias == def_local:
                    marks.append("default-local")
                if alias == def_cloud:
                    marks.append("default-cloud")
                marker = f" [{' | '.join(marks)}]" if marks else ""
                lines.append(
                    f"{icon} `{alias}`{marker} ‚Äî {row.get('title')} | {row.get('channel')}/{row.get('provider')} | {cost_text}{reason}"
                )
            lines.append("\n_–í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏:_ `!img --model <alias> <–ø—Ä–æ–º–ø—Ç>`")
            lines.append("_–î–µ—Ñ–æ–ª—Ç—ã:_ `!img default show|local <alias>|cloud <alias>|mode local|cloud|auto`")
            await message.reply_text("\n".join(lines))
            return

        if head == "cost":
            if not hasattr(image_gen, "estimate_cost"):
                await message.reply_text("‚ö†Ô∏è –í —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏ image manager –Ω–µ—Ç –∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä–∞ —Å—Ç–æ–∏–º–æ—Å—Ç–∏.")
                return
            if len(args) >= 2:
                aliases = [args[1]]
            else:
                aliases = list(getattr(image_gen, "model_specs", {}).keys())
            lines = ["**üí∏ Image Cost (–æ—Ä–∏–µ–Ω—Ç–∏—Ä–æ–≤–æ—á–Ω–æ):**", ""]
            for alias in aliases:
                info = image_gen.estimate_cost(alias, images=1)
                if not info.get("ok"):
                    lines.append(f"- `{alias}`: ‚ùå {info.get('error')}")
                    continue
                unit = info.get("unit_cost_usd")
                if unit is None:
                    lines.append(f"- `{alias}`: n/a")
                else:
                    lines.append(f"- `{alias}`: ~`${unit}` –∑–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            await message.reply_text("\n".join(lines))
            return

        model_alias = None
        prefer_local = None
        aspect_ratio = "1:1"
        prompt_tokens: list[str] = []
        idx = 0
        while idx < len(args):
            token = args[idx]
            lowered = token.strip().lower()
            if lowered in {"--model", "-m"} and idx + 1 < len(args):
                model_alias = args[idx + 1].strip()
                idx += 2
                continue
            if lowered == "--local":
                prefer_local = True
                idx += 1
                continue
            if lowered == "--cloud":
                prefer_local = False
                idx += 1
                continue
            if lowered in {"--ar", "--aspect"} and idx + 1 < len(args):
                aspect_ratio = args[idx + 1].strip()
                idx += 2
                continue
            prompt_tokens.append(token)
            idx += 1

        prompt = " ".join(prompt_tokens).strip()
        if not prompt:
            await message.reply_text("‚ùå –í–≤–µ–¥–∏ –æ–ø–∏—Å–∞–Ω–∏–µ –∫–∞—Ä—Ç–∏–Ω–∫–∏: `!img –∫–æ—Ç–∏–∫ –≤ –∫–æ—Å–º–æ—Å–µ`")
            return

        notification = await message.reply_text("üé® **–ì–µ–Ω–µ—Ä–∏—Ä—É—é –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...**")

        if hasattr(image_gen, "generate_with_meta"):
            result = await image_gen.generate_with_meta(
                prompt=prompt,
                aspect_ratio=aspect_ratio,
                model_alias=model_alias,
                prefer_local=prefer_local,
            )
            image_path = result.get("path")
        else:
            result = {"ok": False, "error": "legacy_image_manager"}
            image_path = await image_gen.generate(prompt, aspect_ratio=aspect_ratio)
            if image_path:
                result = {
                    "ok": True,
                    "path": image_path,
                    "model_alias": model_alias or "legacy",
                    "channel": "cloud",
                    "provider": "legacy",
                    "model_id": "legacy",
                    "cost_estimate_usd": None,
                }

        if result.get("ok") and image_path and os.path.exists(image_path):
            await notification.delete()
            cost = result.get("cost_estimate_usd")
            cost_text = f"~`${cost}`" if cost is not None else "n/a"
            caption = (
                f"üé® **–ó–∞–ø—Ä–æ—Å:** `{prompt}`\\n"
                f"Model: `{result.get('model_alias', '-')}`\\n"
                f"Channel: `{result.get('channel', '-')}` | Provider: `{result.get('provider', '-')}`\\n"
                f"Cost est.: {cost_text}"
            )
            await message.reply_photo(photo=image_path, caption=caption)
            os.remove(image_path)
            return

        details = result.get("details")
        details_text = f"\n{details}" if details else ""
        await notification.edit_text(
            "‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ.\\n"
            f"–ü—Ä–∏—á–∏–Ω–∞: `{result.get('error', 'unknown')}`{details_text}\\n"
            "_–ü—Ä–æ–≤–µ—Ä—å `!img models` –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∫–ª—é—á–µ–π/workflow._"
        )

    # --- !exec: Python REPL (Owner only, –æ–ø–∞—Å–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞) ---
    @app.on_message(filters.command("exec", prefixes="!"))
    @safe_handler
    async def exec_command(client, message: Message):
        """Python REPL: !exec <code> (Owner Only)"""
        if not is_superuser(message):
            logger.warning(
                f"‚õî Unauthorized exec attempt from @{message.from_user.username}"
            )
            return

        if message.chat.type != enums.ChatType.PRIVATE:
            await message.reply_text("‚õî `!exec` —Ä–∞–∑—Ä–µ—à–µ–Ω —Ç–æ–ª—å–∫–æ –≤ –ª–∏—á–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è—Ö.")
            await _danger_audit(message, "exec", "blocked", "non-private-chat")
            return

        if len(message.command) < 2:
            await message.reply_text("üêç –í–≤–µ–¥–∏ Python –∫–æ–¥: `!exec print('hello')`")
            return

        code = message.text.split(" ", 1)[1]
        notification = await message.reply_text("üêç **–í—ã–ø–æ–ª–Ω—è—é...**")

        # –ü–µ—Ä–µ—Ö–≤–∞—Ç stdout
        old_stdout = sys.stdout
        sys.stdout = buffer = StringIO()
        # –ö–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è REPL (–ø—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
        exec_globals = {
            "client": client,
            "ctx": client,
            "message": message,
            "msg": message,
            "deps": deps,
            "router": router,
            "mr": router,
            "lms": router,
            "sys": sys,
            "os": os,
            "asyncio": asyncio,
            "logger": logger,
            "traceback": traceback,
        }
        
        try:
            exec(code, exec_globals)  # noqa: S102
            output = buffer.getvalue() or "‚úÖ –í—ã–ø–æ–ª–Ω–µ–Ω–æ (–Ω–µ—Ç –≤—ã–≤–æ–¥–∞)"
        except Exception as e:
            output = f"‚ùå {type(e).__name__}: {e}\n{traceback.format_exc()[-500:]}"
        finally:
            sys.stdout = old_stdout

        if len(output) > 4000:
            output = output[:3900] + "\n...[Truncated]..."

        # –û—á–∏—â–∞–µ–º –≤—ã–≤–æ–¥ –æ—Ç –≤–ª–æ–∂–µ–Ω–Ω—ã—Ö –±—ç–∫—Ç–∏–∫–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ª–æ–º–∞—é—Ç markdown
        safe_output = strip_backticks_from_content(output)
        await notification.edit_text(f"üêç **–†–µ–∑—É–ª—å—Ç–∞—Ç:**\n\n```\n{safe_output}\n```")
        await _danger_audit(message, "exec", "ok", code[:300])

    async def _enqueue_direct_auto_reply_task(client, message: Message) -> None:
        """
        –ü–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –æ–¥–Ω–æ–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥—å/–ø—Ä—è–º–æ–π —Ä–∞–Ω.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏ –Ω–∞–ø—Ä—è–º—É—é, –∏ –ø–æ—Å–ª–µ burst-—Å–∫–ª–µ–π–∫–∏ —Ñ–æ—Ä–≤–∞—Ä–¥–æ–≤.
        """
        chat_id = int(message.chat.id)
        message_id = int(message.id)
        if _is_duplicate_message(chat_id, message_id):
            logger.debug("Skipping duplicate update in auto-reply enqueue", chat_id=chat_id, message_id=message_id)
            return

        async def _runner():
            await _process_auto_reply(client, message, deps)

        if not ai_runtime.queue_enabled:
            logger.debug(
                "auto_reply_logic: –æ—á–µ—Ä–µ–¥—å –≤—ã–∫–ª—é—á–µ–Ω–∞, –≤—ã–ø–æ–ª–Ω—è—é –∑–∞–ø—Ä–æ—Å —Å—Ä–∞–∑—É",
                chat_id=chat_id,
                message_id=message_id,
            )
            await _runner()
            return

        queued_task = ChatQueuedTask(
            chat_id=chat_id,
            message_id=message_id,
            received_at=time.time(),
            priority=0,
            runner=_runner,
        )
        accepted, queue_size = queue_manager.enqueue(queued_task)
        if not accepted:
            if message.chat.type == enums.ChatType.PRIVATE:
                await message.reply_text(
                    "‚ö†Ô∏è –û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ –¥–ª—è —ç—Ç–æ–≥–æ —á–∞—Ç–∞. –ü–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –∏ –ø–æ–≤—Ç–æ—Ä–∏."
                )
            return

        queue_manager.ensure_worker(chat_id)
        queue_log_fn = logger.info if message.chat.type == enums.ChatType.PRIVATE else logger.debug
        queue_log_fn(
            "auto_reply_logic: –∑–∞–¥–∞—á–∞ –ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ –æ—á–µ—Ä–µ–¥—å",
            chat_id=chat_id,
            message_id=message_id,
            queue_size=queue_size,
        )
        now = time.time()
        last_notice = _LAST_BUSY_NOTICE_TS.get(chat_id, 0.0)
        if (
            bool(ai_runtime and ai_runtime.queue_notify_position_enabled)
            and message.chat.type == enums.ChatType.PRIVATE
            and queue_size > 1
            and (now - last_notice) >= AUTO_REPLY_BUSY_NOTICE_SECONDS
        ):
            _LAST_BUSY_NOTICE_TS[chat_id] = now
            try:
                await message.reply_text(f"üßæ –î–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ–∑–∏—Ü–∏—è: {queue_size}).")
            except Exception:
                pass

    async def _flush_forward_burst(client, burst_key: str) -> None:
        """
        –§–ª–∞—à–∏—Ç –Ω–∞–∫–æ–ø–ª–µ–Ω–Ω—É—é –ø–∞—á–∫—É —Ñ–æ—Ä–≤–∞—Ä–¥–æ–≤ –æ–¥–Ω–∏–º –∑–∞–¥–∞–Ω–∏–µ–º.
        """
        await asyncio.sleep(AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS)
        payload = forward_burst_buffers.pop(burst_key, None)
        if not payload:
            return

        messages = list(payload.get("messages") or [])
        if not messages:
            return
        tail = messages[-max(1, int(AUTO_REPLY_FORWARD_BURST_MAX_ITEMS)) :]
        anchor_message = tail[-1]
        if len(tail) > 1:
            context_text = _compose_forward_burst_context(
                tail[:-1],
                max_items=AUTO_REPLY_FORWARD_BURST_MAX_ITEMS,
            )
            if context_text:
                context_key = f"{int(anchor_message.chat.id)}:{int(anchor_message.id)}"
                _FORWARD_BURST_CONTEXT_MAP[context_key] = context_text
        await _enqueue_direct_auto_reply_task(client, anchor_message)

    async def _enqueue_auto_reply_task(client, message: Message) -> None:
        """
        –£–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –ø–æ—Å—Ç–∞–Ω–æ–≤–∫–∞ auto-reply –∑–∞–¥–∞—á–∏ –≤ –æ—á–µ—Ä–µ–¥—å.
        –î–ª—è –ø–µ—Ä–µ—Å–ª–∞–Ω–Ω–æ–π ¬´–ø–∞—á–∫–∏¬ª –≤–∫–ª—é—á–∞–µ—Ç –∫–æ—Ä–æ—Ç–∫–æ–µ –æ–∫–Ω–æ —Å–∫–ª–µ–π–∫–∏.
        """
        if _is_forwarded_message(message):
            sender_id = int(getattr(getattr(message, "from_user", None), "id", 0) or 0)
            burst_key = f"{int(message.chat.id)}:{sender_id}"
            state = forward_burst_buffers.get(burst_key)
            if not state:
                state = {"messages": [], "task": None}
                forward_burst_buffers[burst_key] = state
            added = _append_forward_to_burst_state(
                state,
                message,
                max_items=AUTO_REPLY_FORWARD_BURST_MAX_ITEMS,
            )
            if not added:
                logger.debug(
                    "auto_reply_logic: –¥—É–±–ª–∏–∫–∞—Ç —Ñ–æ—Ä–≤–∞—Ä–¥–∞ –ø—Ä–æ–ø—É—â–µ–Ω –≤ burst-–±—É—Ñ–µ—Ä–µ",
                    chat_id=message.chat.id,
                    message_id=message.id,
                    burst_key=burst_key,
                    burst_size=len(state.get("messages") or []),
                )
                return
            pending_task = state.get("task")
            if pending_task and not pending_task.done():
                pending_task.cancel()
            state["task"] = asyncio.create_task(_flush_forward_burst(client, burst_key))
            logger.debug(
                "auto_reply_logic: —Ñ–æ—Ä–≤–∞—Ä–¥ –¥–æ–±–∞–≤–ª–µ–Ω –≤ burst-–±—É—Ñ–µ—Ä",
                chat_id=message.chat.id,
                message_id=message.id,
                burst_key=burst_key,
                burst_size=len(state["messages"]),
                window_sec=AUTO_REPLY_FORWARD_BURST_WINDOW_SECONDS,
            )
            return

        await _enqueue_direct_auto_reply_task(client, message)

    # --- –ê–≤—Ç–æ-–æ—Ç–≤–µ—Ç (—Å–∞–º—ã–π –ø–æ—Å–ª–µ–¥–Ω–∏–π, –ª–æ–≤–∏—Ç —Ç–µ–∫—Å—Ç + –º–µ–¥–∏–∞) ---
    @app.on_message(
        (
            filters.text
            | filters.photo
            | filters.voice
            | filters.audio
            | filters.sticker
            | filters.animation
            | filters.video
            | filters.document
        )
        & ~filters.me
        & ~filters.bot
        ,
        group=9,
    )
    @safe_handler
    async def auto_reply_logic(client, message: Message):
        """
        –£–º–Ω—ã–π –∞–≤—Ç–æ–æ—Ç–≤–µ—Ç—á–∏–∫ v2 (Omni-channel).
        –î–µ–ª–µ–≥–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª–Ω–µ–Ω–∏–µ –≤ _process_auto_reply.
        """
        text = str(getattr(message, "text", "") or "").strip()
        if text.startswith("!"):
            # –ö–æ–º–∞–Ω–¥—ã –¥–æ–ª–∂–Ω—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —Ç–æ–ª—å–∫–æ command-handler'–∞–º–∏.
            return

        if message.chat.type == enums.ChatType.PRIVATE:
            logger.info(
                "auto_reply_logic: –ø–æ–ª—É—á–µ–Ω–æ –ø—Ä–∏–≤–∞—Ç–Ω–æ–µ –≤—Ö–æ–¥—è—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
                chat_id=message.chat.id,
                message_id=message.id,
                sender=getattr(getattr(message, "from_user", None), "username", None),
            )
        await _enqueue_auto_reply_task(client, message)

    @app.on_message(
        filters.private & ~filters.me & ~filters.bot,
        group=8,
    )
    @safe_handler
    async def auto_reply_private_failsafe_logic(client, message: Message):
        """
        Failsafe –¥–ª—è –ª–∏—á–Ω—ã—Ö —á–∞—Ç–æ–≤.
        –ï—Å–ª–∏ –ø–æ –∫–∞–∫–∏–º-—Ç–æ –ø—Ä–∏—á–∏–Ω–∞–º –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∏–ª—å—Ç—Ä –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª, —ç—Ç–æ—Ç –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
        –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ –ø–æ–¥—Ö–≤–∞—Ç–∏—Ç –≤—Ö–æ–¥—è—â–µ–µ –∏ –æ—Ç–ø—Ä–∞–≤–∏—Ç –≤ –æ–±—â–∏–π pipeline.
        """
        text = str(getattr(message, "text", "") or "").strip()
        if text.startswith("!"):
            return

        logger.info(
            "auto_reply_failsafe: –ø–æ–ª—É—á–µ–Ω–æ –≤—Ö–æ–¥—è—â–µ–µ –≤ –ª–∏—á–∫–µ",
            chat_id=message.chat.id,
            message_id=message.id,
            sender=getattr(getattr(message, "from_user", None), "username", None),
        )
        await _enqueue_auto_reply_task(client, message)

    @app.on_message(
        (
            filters.text
            | filters.photo
            | filters.voice
            | filters.audio
            | filters.sticker
            | filters.animation
            | filters.video
            | filters.document
        )
        & filters.me
        & ~filters.bot
        ,
        group=9,
    )
    @safe_handler
    async def auto_reply_self_private_logic(client, message: Message):
        """
        –ê–≤—Ç–æ–æ—Ç–≤–µ—Ç –≤ ¬´—á–∞—Ç–µ —Å —Å–æ–±–æ–π¬ª (self private).
        –ù—É–∂–µ–Ω –¥–ª—è —Å—Ü–µ–Ω–∞—Ä–∏—è, –∫–æ–≥–¥–∞ –≤–ª–∞–¥–µ–ª–µ—Ü –ø–∏—à–µ—Ç –≤ –ª–∏—á–∫—É —Å–∞–º–æ–º—É –∞–∫–∫–∞—É–Ω—Ç—É
        –∏ –æ–∂–∏–¥–∞–µ—Ç –æ–±—ã—á–Ω—ã–π AI-–æ—Ç–≤–µ—Ç –±–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å–∞ –∫–æ–º–∞–Ω–¥—ã.
        """
        if not AUTO_REPLY_SELF_PRIVATE_ENABLED:
            return
        if not _is_self_private_message(message):
            return

        text = str(getattr(message, "text", "") or "").strip()
        if text.startswith("!"):
            # –ö–æ–º–∞–Ω–¥—ã –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ command-handler'–∞–º–∏.
            return

        # –ó–∞—â–∏—Ç–∞ –æ—Ç –∑–∞—Ü–∏–∫–ª–∏–≤–∞–Ω–∏—è: —Å–æ–æ–±—â–µ–Ω–∏—è-–æ—Ç–≤–µ—Ç—ã, —Å–æ–∑–¥–∞–Ω–Ω—ã–µ —Å–∞–º–∏–º –±–æ—Ç–æ–º,
        # –≤—Å–µ–≥–¥–∞ —è–≤–ª—è—é—Ç—Å—è reply –∏ –Ω–µ –¥–æ–ª–∂–Ω—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ –∏–¥—Ç–∏ –≤ auto-reply.
        if getattr(message, "reply_to_message", None):
            reply_from = getattr(message.reply_to_message, "from_user", None)
            if reply_from and bool(getattr(reply_from, "is_self", False)):
                return

        chat_id = int(message.chat.id)
        message_id = int(message.id)
        if _is_duplicate_message(chat_id, message_id):
            return

        async def _runner():
            await _process_auto_reply(client, message, deps)

        if not ai_runtime.queue_enabled:
            await _runner()
            return

        queued_task = ChatQueuedTask(
            chat_id=chat_id,
            message_id=message_id,
            received_at=time.time(),
            priority=0,
            runner=_runner,
        )
        accepted, queue_size = queue_manager.enqueue(queued_task)
        if not accepted:
            await message.reply_text("‚ö†Ô∏è –û—á–µ—Ä–µ–¥—å –ø–µ—Ä–µ–ø–æ–ª–Ω–µ–Ω–∞ –¥–ª—è self-—á–∞—Ç–∞. –ü–æ–¥–æ–∂–¥–∏ –ø–∞—Ä—É —Å–µ–∫—É–Ω–¥ –∏ –ø–æ–≤—Ç–æ—Ä–∏.")
            return

        queue_manager.ensure_worker(chat_id)
        now = time.time()
        last_notice = _LAST_BUSY_NOTICE_TS.get(chat_id, 0.0)
        if (
            bool(ai_runtime and ai_runtime.queue_notify_position_enabled)
            and queue_size > 1
            and (now - last_notice) >= AUTO_REPLY_BUSY_NOTICE_SECONDS
        ):
            _LAST_BUSY_NOTICE_TS[chat_id] = now
            try:
                await message.reply_text(f"üßæ –î–æ–±–∞–≤–∏–ª –≤ –æ—á–µ—Ä–µ–¥—å –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ–∑–∏—Ü–∏—è: {queue_size}).")
            except Exception:
                pass
