# -*- coding: utf-8 -*-
"""Multimodal Module

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14nwK0xjjNETf0WZaRHpDGGjPzDs4reBf
"""

# -*- coding: utf-8 -*-
"""
Perceptor Module (Eyes & Ears).
–û—Ç–≤–µ—á–∞–µ—Ç –∑–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—é –∞—É–¥–∏–æ –∏ –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π.
–£–º–µ–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å HEIC -> JPG –Ω–∞ –ª–µ—Ç—É.
"""

import os
import asyncio
import logging
import time
from typing import Dict, Any
from io import BytesIO
from PIL import Image
from pillow_heif import register_heif_opener
from pathlib import Path

# –†–µ–≥–∏—Å—Ç—Ä–∏—Ä—É–µ–º –ø–æ–¥–¥–µ—Ä–∂–∫—É HEIC –¥–ª—è Pillow
register_heif_opener()

logger = logging.getLogger(__name__)

# Gemini SDK (New v1.0+)
try:
    from google import genai
    from google.genai import types
    _GENAI_AVAILABLE = True
except ImportError:
    _GENAI_AVAILABLE = False
    genai = None

class Perceptor:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        # Whisper-–º–æ–¥–µ–ª—å –∏–∑ –∫–æ–Ω—Ñ–∏–≥–∞ –≤–º–µ—Å—Ç–æ —Ö–∞—Ä–¥–∫–æ–¥–∞
        self.whisper_model = config.get("WHISPER_MODEL", os.getenv("WHISPER_MODEL", "mlx-community/whisper-large-v3-turbo"))
        # Vision-–º–æ–¥–µ–ª—å –∏–∑ .env (—É–±—Ä–∞–ª–∏ —Ö–∞—Ä–¥–∫–æ–¥ gemini-2.0-flash)
        self.vision_model = os.getenv("GEMINI_VISION_MODEL", "gemini-2.0-flash")
        
        self.gemini_key = config.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
        
        logger.info(f"üëÇ Perceptor initialized. Audio: {self.whisper_model}, Vision: {self.vision_model}")
        
        # Warmup MLX
        self._warmup_audio()

    def _warmup_audio(self):
        """–ü—Ä–æ–≥—Ä–µ–≤ Neural Engine –¥–ª—è MLX Whisper."""
        try:
            import mlx_whisper
            import numpy as np
            logger.info("üî• Warming up Neural Engine (MLX)...")
            # –ü—Ä–æ–≥—Ä–µ–≤ —Ç–∏—à–∏–Ω–æ–π
            mlx_whisper.transcribe(np.zeros(16000, dtype=np.float32), path_or_hf_repo=self.whisper_model)
            logger.info("‚úÖ MLX Audio Model Ready.")
        except Exception as e:
            logger.warning(f"MLX Warmup Skipped: {e}")

    async def transcribe(self, file_path: str, router) -> str:
        """
        –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —Å –ø–æ–º–æ—â—å—é MLX Whisper (Local).
        """
        try:
            logger.info(f"üé§ Transcribing: {file_path}")
            import mlx_whisper
            
            start_time = time.time()
            
            # –ü—Ä–æ–º–ø—Ç-–ø–æ–¥—Å–∫–∞–∑–∫–∞ –¥–ª—è Whisper
            punctuation_prompt = "–ü—Ä–∏–≤–µ—Ç, —è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –ø—É–Ω–∫—Ç—É–∞—Ü–∏–µ–π, –∑–∞–≥–ª–∞–≤–Ω—ã–º–∏ –±—É–∫–≤–∞–º–∏ –∏ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ–º."
            
            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤ executor, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å event loop (MLX —Ç—è–∂–µ–ª—ã–π)
            # –•–æ—Ç—è mlx_whisper –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω, –ª—É—á—à–µ –ø–µ—Ä–µ—Å—Ç—Ä–∞—Ö–æ–≤–∞—Ç—å—Å—è
            result = await asyncio.to_thread(
                mlx_whisper.transcribe,
                file_path, 
                path_or_hf_repo=self.whisper_model,
                initial_prompt=punctuation_prompt,
                language="ru",       # –§–æ—Ä—Å–∏—Ä—É–µ–º —Ä—É—Å—Å–∫–∏–π
                temperature=0.0,     # –£–±–∏—Ä–∞–µ–º –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–∏
                verbose=False
            )
            
            text = result.get("text", "").strip()
            duration = time.time() - start_time
            
            logger.info(f"‚úÖ Transcribed in {duration:.2f}s: {text[:50]}...")
            return text

        except Exception as e:
            logger.error(f"‚ùå Local Transcription Failed: {e}")
            return f"–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {e}"

    async def analyze_image(self, file_path: str, router, prompt: str) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç HEIC.
        """
        converted_path = file_path

        try:
            # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º–∞—Ç–∞ –∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if str(file_path).lower().endswith(".heic"):
                img = Image.open(file_path)
                converted_path = f"{file_path}.jpg"
                img.save(converted_path, format="JPEG")
                logger.info(f"Converted HEIC to JPG: {converted_path}")

            # 2. Vision Request via Gemini SDK
            if not _GENAI_AVAILABLE:
                return "–û—à–∏–±–∫–∞: Google GenAI SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."
                
            api_key = router.gemini_key or self.gemini_key
            if not api_key:
                return "–û—à–∏–±–∫–∞: –ù–µ—Ç –∫–ª—é—á–∞ Gemini API."

            client = genai.Client(api_key=api_key)
            
            img = Image.open(converted_path)
            
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=self.vision_model,
                contents=[prompt, img]
            )
            
            if response and response.text:
                 return response.text
            return "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç)."

        except Exception as e:
            logger.error(f"Vision error: {e}")
            return f"–Ø –æ—Å–ª–µ–ø, –ü–æ. –û—à–∏–±–∫–∞: {e}"
        finally:
            # –ß–∏—Å—Ç–∏–º –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–∞–π–ª –µ—Å–ª–∏ –æ–Ω —Å–æ–∑–¥–∞–≤–∞–ª—Å—è
            if converted_path != file_path and os.path.exists(converted_path):
                os.remove(converted_path)

    async def analyze_visual(self, file_path: str, prompt: str) -> str:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–≤–∫–ª—é—á–∞—è —Å–∫—Ä–∏–Ω—à–æ—Ç—ã).
        """
        try:
            if not _GENAI_AVAILABLE:
                return "–û—à–∏–±–∫–∞: Google GenAI SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."

            api_key = self.gemini_key
            if not api_key:
                return "–û—à–∏–±–∫–∞: –ù–µ—Ç –∫–ª—é—á–∞ Gemini API."

            client = genai.Client(api_key=api_key)
            img = Image.open(file_path)
            
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=self.vision_model,
                contents=[prompt, img]
            )
            return response.text if response else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç."

        except Exception as e:
            logger.error(f"Visual analysis error: {e}")
            return f"–û—à–∏–±–∫–∞ –∑—Ä–µ–Ω–∏—è: {e}"

    async def analyze_video(self, file_path: str, router, prompt: str) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∏–¥–µ–æ-—Å–æ–æ–±—â–µ–Ω–∏–µ (–≤–∫–ª—é—á–∞—è –∫—Ä—É–∂–∫–∏) —á–µ—Ä–µ–∑ Gemini 2.0 Flash.
        """
        try:
            if not _GENAI_AVAILABLE:
                return "–û—à–∏–±–∫–∞: Google GenAI SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."

            api_key = router.gemini_key or self.gemini_key
            if not api_key:
                return "–û—à–∏–±–∫–∞: –ù–µ—Ç –∫–ª—é—á–∞ Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∏–¥–µ–æ."

            client = genai.Client(api_key=api_key)
            
            logger.info(f"üéûÔ∏è Uploading video to Gemini: {file_path}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
            video_file = await asyncio.to_thread(
                client.files.upload,
                path=file_path
            )
            
            # –ñ–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
            while True:
                # Polling file status
                # Using to_thread because client methods might be blocking
                file_info = await asyncio.to_thread(client.files.get, name=video_file.name)
                
                # Check status (Assuming 'ACTIVE' or 'PROCESSING')
                # In new SDK, state is an enum or string.
                state = str(file_info.state)
                
                if "ACTIVE" in state:
                    break
                elif "FAILED" in state:
                    raise Exception("Google Video Processing failed.")
                
                logger.info(f"Video processing... {state}")
                await asyncio.sleep(2)

            logger.info(f"‚úÖ Video processing complete: {video_file.name}")
            
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=self.vision_model,
                contents=[prompt, video_file]
            )
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª
            await asyncio.to_thread(client.files.delete, name=video_file.name)
            
            return response.text if response else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø–æ –≤–∏–¥–µ–æ."

        except Exception as e:
            logger.error(f"Video analysis error: {e}")
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∏–¥–µ–æ: {e}"

    async def analyze_document(self, file_path: str, router, prompt: str) -> str:
        """
        –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç (PDF) —á–µ—Ä–µ–∑ Gemini Native Document Understanding.
        """
        try:
            if not _GENAI_AVAILABLE:
                return "–û—à–∏–±–∫–∞: Google GenAI SDK –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω."

            api_key = router.gemini_key or self.gemini_key
            if not api_key:
                return "–û—à–∏–±–∫–∞: –ù–µ—Ç –∫–ª—é—á–∞ Gemini API –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞."

            client = genai.Client(api_key=api_key)
            
            logger.info(f"üìÑ Uploading document to Gemini: {file_path}")
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–∞–π–ª
            doc_file = await asyncio.to_thread(
                client.files.upload,
                path=file_path
            )
            
            # –ñ–¥–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏
            while True:
                file_info = await asyncio.to_thread(client.files.get, name=doc_file.name)
                state = str(file_info.state)
                
                if "ACTIVE" in state:
                    break
                elif "FAILED" in state:
                    raise Exception("Google Document Processing failed.")
                
                logger.info(f"Document processing... {state}")
                await asyncio.sleep(2)

            logger.info(f"‚úÖ Document processing complete: {doc_file.name}")
            
            response = await asyncio.to_thread(
                client.models.generate_content,
                model=self.vision_model,
                contents=[prompt, doc_file]
            )
            
            # –£–¥–∞–ª—è–µ–º —Ñ–∞–π–ª –∏–∑ –æ–±–ª–∞–∫–∞
            await asyncio.to_thread(client.files.delete, name=doc_file.name)
            
            return response.text if response else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É."

        except Exception as e:
            logger.error(f"Document analysis error: {e}")
            return f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç: {e}"

    async def speak(self, text: str, voice: str = "Milena") -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (TTS) —á–µ—Ä–µ–∑ macOS 'say' + ffmpeg.
        –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ .ogg —Ñ–∞–π–ª—É.
        """
        import uuid
        
        file_id = str(uuid.uuid4())
        # Ensure dir exists
        os.makedirs("artifacts/downloads", exist_ok=True)
        
        aiff_path = f"artifacts/downloads/{file_id}.aiff"
        ogg_path = f"artifacts/downloads/{file_id}.ogg"
        
        try:
            logger.info(f"üó£Ô∏è Speaking: {text[:30]}... (Voice: {voice})")
            
            # 1. Generate AIFF
            proc_say = await asyncio.create_subprocess_exec(
                "say", "-v", voice, "-o", aiff_path, text,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await proc_say.communicate()

            if proc_say.returncode != 0:
                logger.error(f"TTS (say) failed: {stderr.decode().strip()}")
                return None
            
            if not os.path.exists(aiff_path):
                logger.error(f"TTS (say) completed but file missing: {aiff_path}")
                return None
            
            # 2. Convert to OGG (Voice Note format)
            proc_ffmpeg = await asyncio.create_subprocess_exec(
                "ffmpeg", "-i", aiff_path, "-c:a", "libopus", "-b:a", "24k", "-y", ogg_path,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            stdout, stderr = await proc_ffmpeg.communicate()
            
            if proc_ffmpeg.returncode != 0:
                 logger.error(f"ffmpeg conversion failed: {stderr.decode().strip()}")
                 return None

            if os.path.exists(aiff_path):
                 os.remove(aiff_path)
            
            if os.path.exists(ogg_path):
                logger.info(f"‚úÖ TTS Generated: {ogg_path}")
                return ogg_path
            return None
            
        except Exception as e:
            logger.error(f"TTS Error: {e}")
            return None