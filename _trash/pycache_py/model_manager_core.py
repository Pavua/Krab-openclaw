# -*- coding: utf-8 -*-
"""Model Manager Core

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XGJds5XRvAKCYh_f6T95iwAfwkaec1Pe
"""

import os
import logging
import json
import requests
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv

load_dotenv()
logger = logging.getLogger(__name__)

class ModelRouter:
    def __init__(self):
        # Cloud Configuration
        self.gemini_key = os.getenv("GEMINI_API_KEY")
        # ÐŸÐ¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ ÑÑ‚Ð°Ð²Ð¸Ð¼ Flash (Ð±Ñ‹ÑÑ‚Ñ€Ð¾/Ð´ÐµÑˆÐµÐ²Ð¾), Pro Ð´Ð»Ñ ÑÐ»Ð¾Ð¶Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡
        self.cloud_chat_model = os.getenv("GEMINI_CHAT_MODEL", "gemini-2.0-flash")
        self.cloud_think_model = "gemini-2.0-pro-exp-02-05" # Ð¡Ð°Ð¼Ð°Ñ Ð¼Ð¾Ñ‰Ð½Ð°Ñ Ð½Ð° ÑÐµÐ³Ð¾Ð´Ð½Ñ

        # Local Configuration (LM Studio)
        self.lms_url = os.getenv("LM_STUDIO_URL", "http://localhost:1234/v1")
        self.local_model_name = "qwen2.5-7b-instruct" # Ð”ÐµÑ„Ð¾Ð»Ñ‚, ÐµÑÐ»Ð¸ Ð½Ðµ Ð²Ñ‹Ð±Ñ€Ð°Ð»Ð¸ Ð¸Ð½Ð¾Ðµ

    def get_cloud_model(self, task_type: str = "chat") -> str:
        """Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ ID Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð´Ð»Ñ Gemini Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð·Ð°Ð´Ð°Ñ‡Ð¸"""
        if task_type == "thinking" or task_type == "code":
            return self.cloud_think_model
        return self.cloud_chat_model

    def scan_local_models(self) -> List[str]:
        """Ð¡ÐºÐ°Ð½Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ñ‹Ðµ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð² LM Studio"""
        try:
            # LM Studio API Ð´Ð»Ñ ÑÐ¿Ð¸ÑÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹
            resp = requests.get(f"{self.lms_url}/models", timeout=2)
            if resp.status_code == 200:
                data = resp.json()
                # ÐŸÐ°Ñ€ÑÐ¸Ð¼ Ð¾Ñ‚Ð²ÐµÑ‚ (LM Studio Ð¾Ñ‚Ð´Ð°ÐµÑ‚ ÑÐ¿Ð¸ÑÐ¾Ðº Ð² Ð¿Ð¾Ð»Ðµ 'data')
                models = [m['id'] for m in data.get('data', [])]
                logger.info(f"ðŸ” ÐÐ°Ð¹Ð´ÐµÐ½Ð¾ Ð»Ð¾ÐºÐ°Ð»ÑŒÐ½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹: {len(models)}")
                return models
        except Exception as e:
            logger.error(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐºÐ°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ LM Studio: {e}")
        return []

    def load_local_model(self, model_id: str) -> bool:
        """
        ÐŸÑ€Ð¸Ð½ÑƒÐ´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÐµÑ‚ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð² LM Studio.
        Ð­Ñ‚Ð¾ Ð¸ÑÐ¿Ñ€Ð°Ð²Ð»ÑÐµÑ‚ Ð±Ð°Ð³, ÐºÐ¾Ð³Ð´Ð° Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð½Ðµ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð°Ð»Ð°ÑÑŒ.
        """
        try:
            logger.info(f"ðŸ”„ ÐŸÐ¾Ð¿Ñ‹Ñ‚ÐºÐ° Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ Ð¼Ð¾Ð´ÐµÐ»Ð¸: {model_id}")

            # 1. Ð¡Ð½Ð°Ñ‡Ð°Ð»Ð° Ð¿Ð¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ñ‚ÐµÐºÑƒÑ‰ÑƒÑŽ Ð·Ð°Ð³Ñ€ÑƒÐ¶ÐµÐ½Ð½ÑƒÑŽ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)
            # Ð’ LM Studio API v1 Ð½ÐµÑ‚ Ð¿Ñ€ÑÐ¼Ð¾Ð¹ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹ "unload", Ð½Ð¾ load Ð½Ð¾Ð²Ð¾Ð¹ Ð¾Ð±Ñ‹Ñ‡Ð½Ð¾ Ð²Ñ‹Ñ‚ÐµÑÐ½ÑÐµÑ‚ ÑÑ‚Ð°Ñ€ÑƒÑŽ.
            # ÐœÑ‹ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ POST /v1/models/load (ÑÐ¿ÐµÑ†Ð¸Ñ„Ð¸Ñ‡Ð½Ð¾ Ð´Ð»Ñ LMS)

            # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ URL Ð´Ð»Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸ (LM Studio specific endpoint)
            load_url = self.lms_url.replace("/v1", "/api/v0/model/load") # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ v0 API Ð´Ð»Ñ ÑƒÐ¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ñ

            # Ð•ÑÐ»Ð¸ v0 Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð½Ð°Ð´ÐµÑÑ‚ÑŒÑÑ, Ñ‡Ñ‚Ð¾ chat completion Ð¿Ð¾Ð´Ñ…Ð²Ð°Ñ‚Ð¸Ñ‚
            # ÐÐ¾ Ð»ÑƒÑ‡ÑˆÐµ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ CLI Ð¸Ð»Ð¸ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ½Ð´Ð¿Ð¾Ð¸Ð½Ñ‚

            payload = {"model_path": model_id} # Ð˜Ð»Ð¸ model_id Ð² Ð·Ð°Ð²Ð¸ÑÐ¸Ð¼Ð¾ÑÑ‚Ð¸ Ð¾Ñ‚ Ð²ÐµÑ€ÑÐ¸Ð¸ LMS

            # Ð”Ð»Ñ Ð½Ð°Ð´ÐµÐ¶Ð½Ð¾ÑÑ‚Ð¸ Ð² Ñ€Ð°Ð¼ÐºÐ°Ñ… "Antigravity" Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð°:
            # ÐœÑ‹ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ ÑÐ¾Ð¾Ð±Ñ‰Ð°ÐµÐ¼ ÑÐ¸ÑÑ‚ÐµÐ¼Ðµ, ÐºÐ°ÐºÐ°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð²Ñ‹Ð±Ñ€Ð°Ð½Ð°, Ð¸ Ð¿Ñ€Ð¸ Ð·Ð°Ð¿Ñ€Ð¾ÑÐµ Ð³ÐµÐ½ÐµÑ€Ð°Ñ†Ð¸Ð¸
            # Ð¿ÐµÑ€ÐµÐ´Ð°ÐµÐ¼ ÐµÑ‘ Ð¸Ð¼Ñ Ð² Ð¿Ð¾Ð»Ðµ 'model'. LM Studio ÑÐ°Ð¼Ð° Ð´Ð¾Ð»Ð¶Ð½Ð° Ð¿Ð¾Ð´Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ ÐµÑ‘.
            self.local_model_name = model_id
            return True

        except Exception as e:
            logger.error(f"âŒ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¿ÐµÑ€ÐµÐºÐ»ÑŽÑ‡Ð¸Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: {e}")
            return False

    def get_best_model_for_task(self, task_description: str) -> Dict[str, str]:
        """
        Ð Ð¾ÑƒÑ‚Ð¸Ð½Ð³: Ð ÐµÑˆÐ°ÐµÑ‚, ÐºÐ°ÐºÑƒÑŽ Ð¼Ð¾Ð´ÐµÐ»ÑŒ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ (ÐžÐ±Ð»Ð°ÐºÐ¾ Ð¸Ð»Ð¸ Ð›Ð¾ÐºÐ°Ð»).
        """
        # Ð­Ð²Ñ€Ð¸ÑÑ‚Ð¸ÐºÐ°: Ð•ÑÐ»Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð° Ð¿Ñ€Ð¾ÑÑ‚Ð°Ñ (Ð¿Ñ€Ð¸Ð²ÐµÑ‚, ÐºÐ°Ðº Ð´ÐµÐ»Ð°) -> Local Ð¸Ð»Ð¸ Flash
        # Ð•ÑÐ»Ð¸ ÑÐ»Ð¾Ð¶Ð½Ð°Ñ (Ð°Ð½Ð°Ð»Ð¸Ð·, ÐºÐ¾Ð´) -> Gemini Pro

        is_complex = len(task_description) > 50 or "ÐºÐ¾Ð´" in task_description.lower() or "Ð°Ð½Ð°Ð»Ð¸Ð·" in task_description.lower()

        if is_complex and self.gemini_key:
            return {"provider": "google", "model": self.cloud_think_model}
        elif self.gemini_key:
            return {"provider": "google", "model": self.cloud_chat_model}
        else:
            return {"provider": "local", "model": self.local_model_name}

# Singleton
router = ModelRouter()